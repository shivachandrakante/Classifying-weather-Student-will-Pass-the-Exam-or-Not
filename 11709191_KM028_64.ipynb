{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying weather a student will Pass a course or Not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying in the course -> Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Course is a Theory type and in this dataset, we have only 8 Rows, so I am training my models on the entire data except for this course and try to predict (Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np       #Importing Numerical Python(Numpy)\n",
    "import pandas as pd      #Importing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset using read_csv function in pandas library\n",
    "data=pd.read_csv(r'C:\\Users\\Shiva Chandra\\Desktop\\ML\\Project Sem 2 Year 3\\DATA-FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.shape gives us the no.of rows and columns the dataset consists of.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY1</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY147</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY148</td>\n",
       "      <td>B+</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY2</td>\n",
       "      <td>A+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Practical</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY3</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Termid  Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "0  318192  1101776    KVY1     O    87.0    39.0     82.0     89.0   \n",
       "1  318192  1101776  KVY147    A+    87.0    47.0     65.0     85.0   \n",
       "2  318192  1101776  KVY148    B+    84.0    29.0     63.0     77.0   \n",
       "3  318192  1101776    KVY2    A+     NaN     NaN      NaN     82.0   \n",
       "4  318192  1101776    KVY3    A+    87.0    34.0     68.0     89.0   \n",
       "\n",
       "   Course_Att                                     MHRDName  ...  CA_3  CA_4  \\\n",
       "0        88.0  Bachelor of Science (Honours) (Agriculture)  ...   1.0   0.0   \n",
       "1        82.0  Bachelor of Science (Honours) (Agriculture)  ...   0.0   1.0   \n",
       "2        76.0  Bachelor of Science (Honours) (Agriculture)  ...   3.0   5.0   \n",
       "3        74.0  Bachelor of Science (Honours) (Agriculture)  ...   NaN   NaN   \n",
       "4        76.0  Bachelor of Science (Honours) (Agriculture)  ...   2.0  17.0   \n",
       "\n",
       "   Height  Weight  ScholarType  Direction  Gender Medium CourseType  \\\n",
       "0     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "1     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "2     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "3     181      65      Hostler      North  Female  Hindi  Practical   \n",
       "4     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "\n",
       "  ProgramType  \n",
       "0          UG  \n",
       "1          UG  \n",
       "2          UG  \n",
       "3          UG  \n",
       "4          UG  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.head gives us the Top 5 rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Termid', 'Regd No', 'Course', 'Grade', 'CA_100', 'MTT_50', 'ETT_100',\n",
       "       'ETP_100', 'Course_Att', 'MHRDName', 'CA_1', 'CA_2', 'CA_3', 'CA_4',\n",
       "       'Height', 'Weight', 'ScholarType', 'Direction', 'Gender', 'Medium',\n",
       "       'CourseType', 'ProgramType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.columns gives us the name of the columns present in the DataFrame\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, I am trying to get how many i.e no.of uniques courses.\n",
    "data['MHRDName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as the above cell but with the program type column\n",
    "data['ProgramType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UG    64635\n",
       "PG      900\n",
       "Name: ProgramType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By the above cell we Know that there are two type of programs, now in this cell we are trying the how many no.of a program \n",
    "#repeating\n",
    "data['ProgramType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we trying to get unique grades\n",
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CourseType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Termid             0\n",
       "Regd No            0\n",
       "Course             0\n",
       "Grade              0\n",
       "CA_100          2566\n",
       "MTT_50         27121\n",
       "ETT_100        25836\n",
       "ETP_100        35891\n",
       "Course_Att      6081\n",
       "MHRDName           0\n",
       "CA_1            2566\n",
       "CA_2            2566\n",
       "CA_3            2566\n",
       "CA_4            2566\n",
       "Height             0\n",
       "Weight             0\n",
       "ScholarType        0\n",
       "Direction          0\n",
       "Gender             0\n",
       "Medium             0\n",
       "CourseType         0\n",
       "ProgramType        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we are going to get the no.of null values in each column \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>518192</td>\n",
       "      <td>1103776</td>\n",
       "      <td>OLZ7</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Computer Applications (2 Year progra...</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>66</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>418192</td>\n",
       "      <td>1104776</td>\n",
       "      <td>XPH10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Mechanical Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>518192</td>\n",
       "      <td>1105776</td>\n",
       "      <td>KYI12</td>\n",
       "      <td>A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Bachelor of Technology - Master of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>318192</td>\n",
       "      <td>1119776</td>\n",
       "      <td>VJS87</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>182</td>\n",
       "      <td>97</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>518192</td>\n",
       "      <td>1121776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>B+</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182</td>\n",
       "      <td>69</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65351</td>\n",
       "      <td>318192</td>\n",
       "      <td>15391776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>169</td>\n",
       "      <td>96</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65418</td>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX225</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65419</td>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX226</td>\n",
       "      <td>A+</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65459</td>\n",
       "      <td>318192</td>\n",
       "      <td>15416776</td>\n",
       "      <td>AUK538</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Civil Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65467</td>\n",
       "      <td>318192</td>\n",
       "      <td>15417776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>167</td>\n",
       "      <td>47</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "12     518192   1103776    OLZ7    A+    87.0     NaN      NaN     69.0   \n",
       "13     418192   1104776   XPH10     F     0.0     NaN      NaN      0.0   \n",
       "17     518192   1105776   KYI12     A    89.0     NaN      NaN     64.0   \n",
       "95     318192   1119776   VJS87    B+    57.0     NaN      NaN     62.0   \n",
       "113    518192   1121776  UDK100    B+    80.0     NaN      NaN     64.0   \n",
       "...       ...       ...     ...   ...     ...     ...      ...      ...   \n",
       "65351  318192  15391776   TGE87     O    88.0     NaN      NaN     82.0   \n",
       "65418  418192  15408776  OXX225     O    87.0     NaN      NaN     81.0   \n",
       "65419  418192  15408776  OXX226    A+    88.0     NaN      NaN     87.0   \n",
       "65459  318192  15416776  AUK538    B+    57.0     NaN      NaN     64.0   \n",
       "65467  318192  15417776   CFB87     O    90.0     NaN      NaN     75.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "12            NaN  Master of Computer Applications (2 Year progra...  ...   \n",
       "13            NaN   Bachelor of Technology in Mechanical Engineering  ...   \n",
       "17            NaN  Integrated Bachelor of Technology - Master of ...  ...   \n",
       "95            NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "113           NaN                           Bachelor of Architecture  ...   \n",
       "...           ...                                                ...  ...   \n",
       "65351         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65418         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65419         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65459         NaN         Bachelor of Technology (Civil Engineering)  ...   \n",
       "65467         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "\n",
       "       CA_3  CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "12     16.0   1.0     170      66      Hostler       West    Male  Regional   \n",
       "13      0.0   0.0     163      67  Day Scholar       East    Male   English   \n",
       "17      4.0  18.0     155      75      Hostler      North  Female  Regional   \n",
       "95     10.0   9.0     182      97  Day Scholar      South    Male     Hindi   \n",
       "113     3.0   4.0     182      69  Day Scholar      North    Male  Regional   \n",
       "...     ...   ...     ...     ...          ...        ...     ...       ...   \n",
       "65351  53.0  16.0     169      96      Hostler       East    Male  Regional   \n",
       "65418   1.0   0.0     173      86      Hostler      North    Male  Regional   \n",
       "65419   7.0  38.0     173      86      Hostler      North    Male  Regional   \n",
       "65459   0.0   0.0     150      73  Day Scholar       West    Male   English   \n",
       "65467  12.0  54.0     167      47  Day Scholar       East    Male   English   \n",
       "\n",
       "      CourseType ProgramType  \n",
       "12        Theory          PG  \n",
       "13        Theory          UG  \n",
       "17        Theory          UG  \n",
       "95        Theory          UG  \n",
       "113       Theory          UG  \n",
       "...          ...         ...  \n",
       "65351     Theory          UG  \n",
       "65418     Theory          UG  \n",
       "65419     Theory          UG  \n",
       "65459     Theory          UG  \n",
       "65467     Theory          UG  \n",
       "\n",
       "[4480 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this we are checking the data which have more than or equal to 3 null values in a row and the course type is not practical\n",
    "h=data[data['CourseType']!='Practical']\n",
    "h=h[h.isnull().sum(axis=1)>=3]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>38414.000000</td>\n",
       "      <td>39699.000000</td>\n",
       "      <td>29644.000000</td>\n",
       "      <td>59454.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>288099.682918</td>\n",
       "      <td>8.450856e+06</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.052470</td>\n",
       "      <td>67.181892</td>\n",
       "      <td>81.046692</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.945910</td>\n",
       "      <td>167.077134</td>\n",
       "      <td>70.074922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>84391.200813</td>\n",
       "      <td>4.155810e+06</td>\n",
       "      <td>23.809873</td>\n",
       "      <td>11.811316</td>\n",
       "      <td>22.972317</td>\n",
       "      <td>22.770638</td>\n",
       "      <td>17.960987</td>\n",
       "      <td>23.197636</td>\n",
       "      <td>16.421255</td>\n",
       "      <td>10.651955</td>\n",
       "      <td>10.654228</td>\n",
       "      <td>10.138942</td>\n",
       "      <td>17.785183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>118192.000000</td>\n",
       "      <td>1.101776e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>218192.000000</td>\n",
       "      <td>4.875776e+06</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>318192.000000</td>\n",
       "      <td>8.474776e+06</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>318192.000000</td>\n",
       "      <td>1.203578e+07</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>718192.000000</td>\n",
       "      <td>1.543278e+07</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Termid       Regd No        CA_100        MTT_50       ETT_100  \\\n",
       "count   65535.000000  6.553500e+04  62969.000000  38414.000000  39699.000000   \n",
       "mean   288099.682918  8.450856e+06     63.772317     26.110637     52.052470   \n",
       "std     84391.200813  4.155810e+06     23.809873     11.811316     22.972317   \n",
       "min    118192.000000  1.101776e+06      0.000000      0.000000      0.000000   \n",
       "25%    218192.000000  4.875776e+06     54.000000     19.000000     40.000000   \n",
       "50%    318192.000000  8.474776e+06     69.000000     28.000000     56.000000   \n",
       "75%    318192.000000  1.203578e+07     81.000000     35.000000     68.000000   \n",
       "max    718192.000000  1.543278e+07    100.000000     50.000000    100.000000   \n",
       "\n",
       "            ETP_100    Course_Att          CA_1          CA_2          CA_3  \\\n",
       "count  29644.000000  59454.000000  62969.000000  62969.000000  62969.000000   \n",
       "mean      67.181892     81.046692     31.961918     15.926504      7.937985   \n",
       "std       22.770638     17.960987     23.197636     16.421255     10.651955   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       61.000000     76.000000     12.000000      3.000000      1.000000   \n",
       "50%       73.000000     85.000000     29.000000     10.000000      4.000000   \n",
       "75%       82.000000     93.000000     49.000000     24.000000     11.000000   \n",
       "max      100.000000    100.000000    100.000000     94.000000     89.000000   \n",
       "\n",
       "               CA_4        Height        Weight  \n",
       "count  62969.000000  65535.000000  65535.000000  \n",
       "mean       7.945910    167.077134     70.074922  \n",
       "std       10.654228     10.138942     17.785183  \n",
       "min        0.000000    150.000000     40.000000  \n",
       "25%        1.000000    158.000000     55.000000  \n",
       "50%        4.000000    167.000000     70.000000  \n",
       "75%       11.000000    176.000000     85.000000  \n",
       "max       87.000000    184.000000    100.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.describe() the function shows us the different values of the statistical functions applied to the data frame.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell I am a new columns which will contain either pass or fail\n",
    "abc=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    if(data.iloc[i,3])=='ReApp' or (data.iloc[i,3])=='FAIL' or (data.iloc[i,3])=='F' or (data.iloc[i,3])=='E':\n",
    "        abc.append(str('Fail'))\n",
    "    else:\n",
    "        abc.append(str('Passed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A        14184\n",
       "B+       12924\n",
       "A+       10946\n",
       "B         7163\n",
       "C         5710\n",
       "O         4701\n",
       "E         4378\n",
       "F         3338\n",
       "D         1674\n",
       "M          276\n",
       "I          101\n",
       "PASS        64\n",
       "R           52\n",
       "ReApp       15\n",
       "FAIL         6\n",
       "S            3\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #We are Importing the labelencoder from the sklearn.preprocessing \n",
    "label_encoder=LabelEncoder()                   #We are just creating a variable for the function\n",
    "label_encoder.fit(abc)                         #we are fitting the label encoder on our result list\n",
    "abc=label_encoder.transform(abc)               #we are tranforming the list and storing it \n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(abc,columns=['Result'])#This line Converts the abc list into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57798\n",
       "0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 23)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([data,df1],axis=1)  #In this line, we concting two DataFrame i.e the data and justly created result DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=df[df['MHRDName']=='Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 23)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38833</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38834</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ11</td>\n",
       "      <td>E</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38835</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ245</td>\n",
       "      <td>E</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38836</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ246</td>\n",
       "      <td>B+</td>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40904</td>\n",
       "      <td>418192</td>\n",
       "      <td>10373776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>O</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152</td>\n",
       "      <td>74</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "38833  418192   9875776   XHQ10     F     0.0     NaN      NaN     84.0   \n",
       "38834  418192   9875776   XHQ11     E    77.0     NaN      0.0      NaN   \n",
       "38835  418192   9875776  XHQ245     E    72.0    15.0     12.0      NaN   \n",
       "38836  418192   9875776  XHQ246    B+    72.0    28.0     62.0      NaN   \n",
       "40904  418192  10373776   XHQ10     O    83.0     NaN      NaN     90.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "38833         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38834        94.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38835        98.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38836        93.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "40904         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "\n",
       "       CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "38833   0.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38834   4.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38835   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38836   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "40904   0.0     152      74      Hostler      North  Female  Regional   \n",
       "\n",
       "      CourseType ProgramType Result  \n",
       "38833     Theory          UG      0  \n",
       "38834     Theory          UG      0  \n",
       "38835     Theory          UG      0  \n",
       "38836     Theory          UG      1  \n",
       "40904     Theory          UG      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "validation.drop(cols,axis=1,inplace=True)\n",
    "validation_x=validation.drop(['Result'],axis=1)\n",
    "validation_y=validation['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "df=df.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100         2566\n",
       "MTT_50        27121\n",
       "ETT_100       25836\n",
       "ETP_100       35891\n",
       "Course_Att     6081\n",
       "CA_1           2566\n",
       "CA_2           2566\n",
       "CA_3           2566\n",
       "CA_4           2566\n",
       "Result            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "im=SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data=im.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns\n",
    "df=pd.DataFrame(imputed_data,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['CA_100']=df['CA_100'].astype(float)\n",
    "# df['MTT_50']=df['MTT_50'].astype(float)\n",
    "# df['ETT_100']=df['ETT_100'].astype(float)\n",
    "# df['Course_Att']=df['Course_Att'].astype(float)\n",
    "# df['Result']=df['Result'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the below cell we are removing the rows which consists course as practical.  Why are we Deleting ?\n",
    "we are deleting because the data we have to predict i.e Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering) is a theory one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=['ETP_100','CA_1','CA_2','CA_3','CA_4','Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "#       ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "# train_data=df.drop(cols,axis=1)\n",
    "train_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data.isnull().sum(axis=1)<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    57798\n",
       "0.0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=train_data.dropna()\n",
    "arr=result['Result']\n",
    "result=result.drop(['Result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=ss.fit_transform(result)\n",
    "abc.reshape(-1,1)\n",
    "abc.shape\n",
    "cols=result.columns\n",
    "result=pd.DataFrame(abc,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>1.425380e+00</td>\n",
       "      <td>1.674976e+00</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>0.406454</td>\n",
       "      <td>3.974745e-01</td>\n",
       "      <td>1.806207</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-0.760849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>2.310066e+00</td>\n",
       "      <td>7.241599e-01</td>\n",
       "      <td>1.163488</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>2.376473e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-0.665095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.666940e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>6.122992e-01</td>\n",
       "      <td>0.641104</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>1.936696e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-4.729303e-01</td>\n",
       "      <td>-0.282081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.044457e-16</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.967594</td>\n",
       "      <td>-0.411912</td>\n",
       "      <td>-1.562403e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.506435e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>8.724513e-01</td>\n",
       "      <td>8.919510e-01</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>4.414522e-01</td>\n",
       "      <td>0.625822</td>\n",
       "      <td>-5.687043e-01</td>\n",
       "      <td>0.866961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CA_100        MTT_50       ETT_100   ETP_100  Course_Att  \\\n",
       "0  9.952347e-01  1.425380e+00  1.674976e+00  1.424680    0.406454   \n",
       "1  9.952347e-01  2.310066e+00  7.241599e-01  1.163488    0.055725   \n",
       "2  8.666940e-01  3.195225e-01  6.122992e-01  0.641104   -0.295003   \n",
       "3  3.044457e-16  3.928796e-16 -3.974090e-16  0.967594   -0.411912   \n",
       "4  9.952347e-01  8.724513e-01  8.919510e-01  1.424680   -0.295003   \n",
       "\n",
       "           CA_1      CA_2          CA_3      CA_4  \n",
       "0  3.974745e-01  1.806207 -6.644782e-01 -0.760849  \n",
       "1  2.376473e+00 -0.989443 -7.602521e-01 -0.665095  \n",
       "2  1.936696e+00 -0.989443 -4.729303e-01 -0.282081  \n",
       "3 -1.562403e-16  0.000000 -8.506435e-17  0.000000  \n",
       "4  4.414522e-01  0.625822 -5.687043e-01  0.866961  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.745519e-15</td>\n",
       "      <td>-1.782266e-15</td>\n",
       "      <td>-2.145025e-16</td>\n",
       "      <td>6.155271e-16</td>\n",
       "      <td>-3.926856e-15</td>\n",
       "      <td>9.516526e-16</td>\n",
       "      <td>-7.370434e-16</td>\n",
       "      <td>-6.777959e-16</td>\n",
       "      <td>-1.110574e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.732447e+00</td>\n",
       "      <td>-2.887465e+00</td>\n",
       "      <td>-2.911313e+00</td>\n",
       "      <td>-4.386848e+00</td>\n",
       "      <td>-4.737561e+00</td>\n",
       "      <td>-1.405613e+00</td>\n",
       "      <td>-9.894431e-01</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-7.608488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-4.187137e-01</td>\n",
       "      <td>-1.228206e-01</td>\n",
       "      <td>-2.934656e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.365482e-01</td>\n",
       "      <td>-8.339024e-01</td>\n",
       "      <td>-8.030664e-01</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-6.650953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.811432e-01</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.141801e-01</td>\n",
       "      <td>-4.230298e-02</td>\n",
       "      <td>-3.060618e-01</td>\n",
       "      <td>-3.771564e-01</td>\n",
       "      <td>-3.778347e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.953063e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>4.445082e-01</td>\n",
       "      <td>2.493151e-01</td>\n",
       "      <td>6.402726e-01</td>\n",
       "      <td>7.053187e-01</td>\n",
       "      <td>5.015706e-01</td>\n",
       "      <td>2.932612e-01</td>\n",
       "      <td>2.924399e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.552245e+00</td>\n",
       "      <td>2.641824e+00</td>\n",
       "      <td>2.681722e+00</td>\n",
       "      <td>2.142959e+00</td>\n",
       "      <td>1.107910e+00</td>\n",
       "      <td>2.992162e+00</td>\n",
       "      <td>4.850360e+00</td>\n",
       "      <td>7.763629e+00</td>\n",
       "      <td>7.569707e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CA_100        MTT_50       ETT_100       ETP_100    Course_Att  \\\n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04   \n",
       "mean   1.745519e-15 -1.782266e-15 -2.145025e-16  6.155271e-16 -3.926856e-15   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.732447e+00 -2.887465e+00 -2.911313e+00 -4.386848e+00 -4.737561e+00   \n",
       "25%   -4.187137e-01 -1.228206e-01 -2.934656e-03  0.000000e+00 -2.365482e-01   \n",
       "50%    1.811432e-01  3.928796e-16 -3.974090e-16  0.000000e+00  1.141801e-01   \n",
       "75%    6.953063e-01  3.195225e-01  4.445082e-01  2.493151e-01  6.402726e-01   \n",
       "max    1.552245e+00  2.641824e+00  2.681722e+00  2.142959e+00  1.107910e+00   \n",
       "\n",
       "               CA_1          CA_2          CA_3          CA_4  \n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  \n",
       "mean   9.516526e-16 -7.370434e-16 -6.777959e-16 -1.110574e-15  \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  \n",
       "min   -1.405613e+00 -9.894431e-01 -7.602521e-01 -7.608488e-01  \n",
       "25%   -8.339024e-01 -8.030664e-01 -6.644782e-01 -6.650953e-01  \n",
       "50%   -4.230298e-02 -3.060618e-01 -3.771564e-01 -3.778347e-01  \n",
       "75%    7.053187e-01  5.015706e-01  2.932612e-01  2.924399e-01  \n",
       "max    2.992162e+00  4.850360e+00  7.763629e+00  7.569707e+00  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=result\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52428, 9)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr1=LogisticRegression(solver='liblinear',C=0.0007)\n",
    "lr2=LogisticRegression(solver='saga',C=0.0007)\n",
    "lr3=LogisticRegression(solver='liblinear',C=0.02)\n",
    "lr4=LogisticRegression(solver='saga',C=0.02)\n",
    "lr5=LogisticRegression(solver='liblinear',C=1)\n",
    "lr6=LogisticRegression(solver='saga',C=1)\n",
    "lr7=LogisticRegression(solver='liblinear',C=3)\n",
    "lr8=LogisticRegression(solver='saga',C=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(x_train,y_train)\n",
    "lr2.fit(x_train,y_train)\n",
    "lr3.fit(x_train,y_train)\n",
    "lr4.fit(x_train,y_train)\n",
    "lr5.fit(x_train,y_train)\n",
    "lr6.fit(x_train,y_train)\n",
    "lr7.fit(x_train,y_train)\n",
    "lr8.fit(x_train,y_train)\n",
    "y_pred1=lr1.predict(x_test)\n",
    "y_pred2=lr2.predict(x_test)\n",
    "y_pred3=lr3.predict(x_test)\n",
    "y_pred4=lr4.predict(x_test)\n",
    "y_pred5=lr5.predict(x_test)\n",
    "y_pred6=lr6.predict(x_test)\n",
    "y_pred7=lr7.predict(x_test)\n",
    "y_pred8=lr8.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716945143816281\n",
      "0.9614709697108416\n",
      "0.974517433432517\n",
      "0.9742885481040665\n",
      "0.9748226138704509\n",
      "0.9748226138704509\n",
      "0.9750514991989013\n",
      "0.9750514991989013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(accuracy_score(y_test,y_pred4))\n",
    "print(accuracy_score(y_test,y_pred5))\n",
    "print(accuracy_score(y_test,y_pred6))\n",
    "print(accuracy_score(y_test,y_pred7))\n",
    "print(accuracy_score(y_test,y_pred8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.89      1514\n",
      "         1.0       0.98      0.99      0.99     11593\n",
      "\n",
      "    accuracy                           0.97     13107\n",
      "   macro avg       0.95      0.92      0.94     13107\n",
      "weighted avg       0.97      0.97      0.97     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x_train,y_train)\n",
    "y_pred=dt.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9792477302204928"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1398,   156],\n",
       "       [  116, 11437]], dtype=int64)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91      1514\n",
      "         1.0       0.99      0.99      0.99     11593\n",
      "\n",
      "    accuracy                           0.98     13107\n",
      "   macro avg       0.94      0.95      0.95     13107\n",
      "weighted avg       0.98      0.98      0.98     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38834</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38835</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38836</td>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40904</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40905</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40906</td>\n",
       "      <td>95.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40907</td>\n",
       "      <td>97.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA_100  MTT_50  ETT_100  ETP_100  Course_Att  CA_1  CA_2  CA_3  CA_4\n",
       "38833     0.0     NaN      NaN     84.0         NaN   0.0   0.0   0.0   0.0\n",
       "38834    77.0     NaN      0.0      NaN        94.0  29.0  44.0   0.0   4.0\n",
       "38835    72.0    15.0     12.0      NaN        98.0  53.0   3.0  15.0   1.0\n",
       "38836    72.0    28.0     62.0      NaN        93.0  55.0  14.0   2.0   1.0\n",
       "40904    83.0     NaN      NaN     90.0         NaN  68.0   9.0   6.0   0.0\n",
       "40905    87.0     NaN     60.0      NaN        84.0  73.0   7.0   1.0   6.0\n",
       "40906    95.0    43.0     83.0      NaN        78.0  42.0  18.0  20.0  15.0\n",
       "40907    97.0    48.0     73.0      NaN        83.0  58.0   4.0  11.0  24.0"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 33.5       , 48.33333333, 84.        , 88.33333333,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [77.        , 33.5       ,  0.        , 87.        , 94.        ,\n",
       "        29.        , 44.        ,  0.        ,  4.        ],\n",
       "       [72.        , 15.        , 12.        , 87.        , 98.        ,\n",
       "        53.        ,  3.        , 15.        ,  1.        ],\n",
       "       [72.        , 28.        , 62.        , 87.        , 93.        ,\n",
       "        55.        , 14.        ,  2.        ,  1.        ],\n",
       "       [83.        , 33.5       , 48.33333333, 90.        , 88.33333333,\n",
       "        68.        ,  9.        ,  6.        ,  0.        ],\n",
       "       [87.        , 33.5       , 60.        , 87.        , 84.        ,\n",
       "        73.        ,  7.        ,  1.        ,  6.        ],\n",
       "       [95.        , 43.        , 83.        , 87.        , 78.        ,\n",
       "        42.        , 18.        , 20.        , 15.        ],\n",
       "       [97.        , 48.        , 73.        , 87.        , 83.        ,\n",
       "        58.        ,  4.        , 11.        , 24.        ]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x=im.fit_transform(validation_x)\n",
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x=ss.fit_transform(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dt.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38833    0\n",
       "38834    0\n",
       "38835    0\n",
       "38836    1\n",
       "40904    1\n",
       "40905    1\n",
       "40906    1\n",
       "40907    1\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validation_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.51763635e+00,  0.00000000e+00, -2.64131939e-16,\n",
       "        -2.00000000e+00,  0.00000000e+00, -2.14123928e+00,\n",
       "        -9.40217155e-01, -9.61661916e-01, -7.83318652e-01],\n",
       "       [ 1.42507718e-01,  0.00000000e+00, -1.79670784e+00,\n",
       "         0.00000000e+00,  9.23313259e-01, -8.27039511e-01,\n",
       "         2.40277717e+00, -9.61661916e-01, -2.91824596e-01],\n",
       "       [-3.02289099e-02, -2.01701529e+00, -1.35062865e+00,\n",
       "         0.00000000e+00,  1.57506380e+00,  2.60574092e-01,\n",
       "        -7.12285723e-01,  1.13650954e+00, -6.60445138e-01],\n",
       "       [-3.02289099e-02, -5.99653193e-01,  5.08034631e-01,\n",
       "         0.00000000e+00,  7.60375625e-01,  3.51208559e-01,\n",
       "         1.23462859e-01, -6.81905722e-01, -6.60445138e-01],\n",
       "       [ 3.49791672e-01,  0.00000000e+00, -2.64131939e-16,\n",
       "         2.00000000e+00,  0.00000000e+00,  9.40332594e-01,\n",
       "        -2.56422860e-01, -1.22393335e-01, -7.83318652e-01],\n",
       "       [ 4.87980974e-01,  0.00000000e+00,  4.33688100e-01,\n",
       "         0.00000000e+00, -7.06063081e-01,  1.16691876e+00,\n",
       "        -4.08377148e-01, -8.21783819e-01, -4.60775678e-02],\n",
       "       [ 7.64359579e-01,  1.03576461e+00,  1.28867321e+00,\n",
       "         0.00000000e+00, -1.68368888e+00, -2.37915476e-01,\n",
       "         4.27371434e-01,  1.83590002e+00,  1.05978406e+00],\n",
       "       [ 8.33454230e-01,  1.58090387e+00,  9.16940553e-01,\n",
       "         0.00000000e+00, -8.69000715e-01,  4.87160260e-01,\n",
       "        -6.36308579e-01,  5.76997150e-01,  2.16564568e+00]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying with the ANN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=9, activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "# 1st Convolutional Layer\n",
    "classifier.add(Dense(output_dim=8,init='uniform',input_dim=9,activation='relu'))\n",
    "classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
    "classifier.add(Dense(output_dim=3,init='uniform',activation='relu'))\n",
    "\n",
    "#output layer\n",
    "classifier.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47185 samples, validate on 5243 samples\n",
      "Epoch 1/10\n",
      "47185/47185 [==============================] - 8s 168us/step - loss: 0.1741 - acc: 0.9289 - val_loss: 0.1026 - val_acc: 0.9762\n",
      "Epoch 2/10\n",
      "47185/47185 [==============================] - 8s 163us/step - loss: 0.0862 - acc: 0.9787 - val_loss: 0.0801 - val_acc: 0.9777\n",
      "Epoch 3/10\n",
      "47185/47185 [==============================] - 8s 161us/step - loss: 0.0701 - acc: 0.9792 - val_loss: 0.0692 - val_acc: 0.9779\n",
      "Epoch 4/10\n",
      "47185/47185 [==============================] - 7s 157us/step - loss: 0.0619 - acc: 0.9799 - val_loss: 0.0613 - val_acc: 0.9783\n",
      "Epoch 5/10\n",
      "47185/47185 [==============================] - 8s 169us/step - loss: 0.0585 - acc: 0.9797 - val_loss: 0.0618 - val_acc: 0.9773\n",
      "Epoch 6/10\n",
      "47185/47185 [==============================] - 8s 175us/step - loss: 0.0578 - acc: 0.9802 - val_loss: 0.0608 - val_acc: 0.9790\n",
      "Epoch 7/10\n",
      "47185/47185 [==============================] - 10s 206us/step - loss: 0.0576 - acc: 0.9800 - val_loss: 0.0610 - val_acc: 0.9783\n",
      "Epoch 8/10\n",
      "47185/47185 [==============================] - 8s 168us/step - loss: 0.0574 - acc: 0.9804 - val_loss: 0.0605 - val_acc: 0.9794\n",
      "Epoch 9/10\n",
      "47185/47185 [==============================] - 8s 161us/step - loss: 0.0572 - acc: 0.9804 - val_loss: 0.0611 - val_acc: 0.9792\n",
      "Epoch 10/10\n",
      "47185/47185 [==============================] - 8s 160us/step - loss: 0.0572 - acc: 0.9806 - val_loss: 0.0613 - val_acc: 0.9792\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(x_train,y_train,verbose=1,validation_split=0.1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9794766155489433\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs of Accuracy and Loss of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
