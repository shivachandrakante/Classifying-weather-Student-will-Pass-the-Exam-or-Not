{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying weather a student will Pass a course or Not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying in the course -> Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Course is a Theory type and in this dataset, we have only 8 Rows, so I am training my models on the entire data except for this course and try to predict (Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np       #Importing Numerical Python(Numpy)\n",
    "import pandas as pd      #Importing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset using read_csv function in pandas library\n",
    "data=pd.read_csv(r'C:\\Users\\Shiva Chandra\\Desktop\\ML\\Project Sem 2 Year 3\\DATA-FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.shape gives us the no.of rows and columns the dataset consists of.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY1</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY147</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY148</td>\n",
       "      <td>B+</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY2</td>\n",
       "      <td>A+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Practical</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY3</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Termid  Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "0  318192  1101776    KVY1     O    87.0    39.0     82.0     89.0   \n",
       "1  318192  1101776  KVY147    A+    87.0    47.0     65.0     85.0   \n",
       "2  318192  1101776  KVY148    B+    84.0    29.0     63.0     77.0   \n",
       "3  318192  1101776    KVY2    A+     NaN     NaN      NaN     82.0   \n",
       "4  318192  1101776    KVY3    A+    87.0    34.0     68.0     89.0   \n",
       "\n",
       "   Course_Att                                     MHRDName  ...  CA_3  CA_4  \\\n",
       "0        88.0  Bachelor of Science (Honours) (Agriculture)  ...   1.0   0.0   \n",
       "1        82.0  Bachelor of Science (Honours) (Agriculture)  ...   0.0   1.0   \n",
       "2        76.0  Bachelor of Science (Honours) (Agriculture)  ...   3.0   5.0   \n",
       "3        74.0  Bachelor of Science (Honours) (Agriculture)  ...   NaN   NaN   \n",
       "4        76.0  Bachelor of Science (Honours) (Agriculture)  ...   2.0  17.0   \n",
       "\n",
       "   Height  Weight  ScholarType  Direction  Gender Medium CourseType  \\\n",
       "0     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "1     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "2     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "3     181      65      Hostler      North  Female  Hindi  Practical   \n",
       "4     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "\n",
       "  ProgramType  \n",
       "0          UG  \n",
       "1          UG  \n",
       "2          UG  \n",
       "3          UG  \n",
       "4          UG  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.head gives us the Top 5 rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Termid', 'Regd No', 'Course', 'Grade', 'CA_100', 'MTT_50', 'ETT_100',\n",
       "       'ETP_100', 'Course_Att', 'MHRDName', 'CA_1', 'CA_2', 'CA_3', 'CA_4',\n",
       "       'Height', 'Weight', 'ScholarType', 'Direction', 'Gender', 'Medium',\n",
       "       'CourseType', 'ProgramType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.columns gives us the name of the columns present in the DataFrame\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, I am trying to get how many i.e no.of uniques courses.\n",
    "data['MHRDName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as the above cell but with the program type column\n",
    "data['ProgramType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UG    64635\n",
       "PG      900\n",
       "Name: ProgramType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By the above cell we Know that there are two type of programs, now in this cell we are trying the how many no.of a program \n",
    "#repeating\n",
    "data['ProgramType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we trying to get unique grades\n",
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CourseType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Termid             0\n",
       "Regd No            0\n",
       "Course             0\n",
       "Grade              0\n",
       "CA_100          2566\n",
       "MTT_50         27121\n",
       "ETT_100        25836\n",
       "ETP_100        35891\n",
       "Course_Att      6081\n",
       "MHRDName           0\n",
       "CA_1            2566\n",
       "CA_2            2566\n",
       "CA_3            2566\n",
       "CA_4            2566\n",
       "Height             0\n",
       "Weight             0\n",
       "ScholarType        0\n",
       "Direction          0\n",
       "Gender             0\n",
       "Medium             0\n",
       "CourseType         0\n",
       "ProgramType        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we are going to get the no.of null values in each column \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>518192</td>\n",
       "      <td>1103776</td>\n",
       "      <td>OLZ7</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Computer Applications (2 Year progra...</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>66</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>418192</td>\n",
       "      <td>1104776</td>\n",
       "      <td>XPH10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Mechanical Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>518192</td>\n",
       "      <td>1105776</td>\n",
       "      <td>KYI12</td>\n",
       "      <td>A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Bachelor of Technology - Master of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>318192</td>\n",
       "      <td>1119776</td>\n",
       "      <td>VJS87</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>182</td>\n",
       "      <td>97</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>518192</td>\n",
       "      <td>1121776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>B+</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182</td>\n",
       "      <td>69</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65351</td>\n",
       "      <td>318192</td>\n",
       "      <td>15391776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>169</td>\n",
       "      <td>96</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65418</td>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX225</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65419</td>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX226</td>\n",
       "      <td>A+</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65459</td>\n",
       "      <td>318192</td>\n",
       "      <td>15416776</td>\n",
       "      <td>AUK538</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Civil Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65467</td>\n",
       "      <td>318192</td>\n",
       "      <td>15417776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>167</td>\n",
       "      <td>47</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "12     518192   1103776    OLZ7    A+    87.0     NaN      NaN     69.0   \n",
       "13     418192   1104776   XPH10     F     0.0     NaN      NaN      0.0   \n",
       "17     518192   1105776   KYI12     A    89.0     NaN      NaN     64.0   \n",
       "95     318192   1119776   VJS87    B+    57.0     NaN      NaN     62.0   \n",
       "113    518192   1121776  UDK100    B+    80.0     NaN      NaN     64.0   \n",
       "...       ...       ...     ...   ...     ...     ...      ...      ...   \n",
       "65351  318192  15391776   TGE87     O    88.0     NaN      NaN     82.0   \n",
       "65418  418192  15408776  OXX225     O    87.0     NaN      NaN     81.0   \n",
       "65419  418192  15408776  OXX226    A+    88.0     NaN      NaN     87.0   \n",
       "65459  318192  15416776  AUK538    B+    57.0     NaN      NaN     64.0   \n",
       "65467  318192  15417776   CFB87     O    90.0     NaN      NaN     75.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "12            NaN  Master of Computer Applications (2 Year progra...  ...   \n",
       "13            NaN   Bachelor of Technology in Mechanical Engineering  ...   \n",
       "17            NaN  Integrated Bachelor of Technology - Master of ...  ...   \n",
       "95            NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "113           NaN                           Bachelor of Architecture  ...   \n",
       "...           ...                                                ...  ...   \n",
       "65351         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65418         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65419         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65459         NaN         Bachelor of Technology (Civil Engineering)  ...   \n",
       "65467         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "\n",
       "       CA_3  CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "12     16.0   1.0     170      66      Hostler       West    Male  Regional   \n",
       "13      0.0   0.0     163      67  Day Scholar       East    Male   English   \n",
       "17      4.0  18.0     155      75      Hostler      North  Female  Regional   \n",
       "95     10.0   9.0     182      97  Day Scholar      South    Male     Hindi   \n",
       "113     3.0   4.0     182      69  Day Scholar      North    Male  Regional   \n",
       "...     ...   ...     ...     ...          ...        ...     ...       ...   \n",
       "65351  53.0  16.0     169      96      Hostler       East    Male  Regional   \n",
       "65418   1.0   0.0     173      86      Hostler      North    Male  Regional   \n",
       "65419   7.0  38.0     173      86      Hostler      North    Male  Regional   \n",
       "65459   0.0   0.0     150      73  Day Scholar       West    Male   English   \n",
       "65467  12.0  54.0     167      47  Day Scholar       East    Male   English   \n",
       "\n",
       "      CourseType ProgramType  \n",
       "12        Theory          PG  \n",
       "13        Theory          UG  \n",
       "17        Theory          UG  \n",
       "95        Theory          UG  \n",
       "113       Theory          UG  \n",
       "...          ...         ...  \n",
       "65351     Theory          UG  \n",
       "65418     Theory          UG  \n",
       "65419     Theory          UG  \n",
       "65459     Theory          UG  \n",
       "65467     Theory          UG  \n",
       "\n",
       "[4480 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this we are checking the data which have more than or equal to 3 null values in a row and the course type is not practical\n",
    "h=data[data['CourseType']!='Practical']\n",
    "h=h[h.isnull().sum(axis=1)>=3]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>38414.000000</td>\n",
       "      <td>39699.000000</td>\n",
       "      <td>29644.000000</td>\n",
       "      <td>59454.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>288099.682918</td>\n",
       "      <td>8.450856e+06</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.052470</td>\n",
       "      <td>67.181892</td>\n",
       "      <td>81.046692</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.945910</td>\n",
       "      <td>167.077134</td>\n",
       "      <td>70.074922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>84391.200813</td>\n",
       "      <td>4.155810e+06</td>\n",
       "      <td>23.809873</td>\n",
       "      <td>11.811316</td>\n",
       "      <td>22.972317</td>\n",
       "      <td>22.770638</td>\n",
       "      <td>17.960987</td>\n",
       "      <td>23.197636</td>\n",
       "      <td>16.421255</td>\n",
       "      <td>10.651955</td>\n",
       "      <td>10.654228</td>\n",
       "      <td>10.138942</td>\n",
       "      <td>17.785183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>118192.000000</td>\n",
       "      <td>1.101776e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>218192.000000</td>\n",
       "      <td>4.875776e+06</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>318192.000000</td>\n",
       "      <td>8.474776e+06</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>318192.000000</td>\n",
       "      <td>1.203578e+07</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>718192.000000</td>\n",
       "      <td>1.543278e+07</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Termid       Regd No        CA_100        MTT_50       ETT_100  \\\n",
       "count   65535.000000  6.553500e+04  62969.000000  38414.000000  39699.000000   \n",
       "mean   288099.682918  8.450856e+06     63.772317     26.110637     52.052470   \n",
       "std     84391.200813  4.155810e+06     23.809873     11.811316     22.972317   \n",
       "min    118192.000000  1.101776e+06      0.000000      0.000000      0.000000   \n",
       "25%    218192.000000  4.875776e+06     54.000000     19.000000     40.000000   \n",
       "50%    318192.000000  8.474776e+06     69.000000     28.000000     56.000000   \n",
       "75%    318192.000000  1.203578e+07     81.000000     35.000000     68.000000   \n",
       "max    718192.000000  1.543278e+07    100.000000     50.000000    100.000000   \n",
       "\n",
       "            ETP_100    Course_Att          CA_1          CA_2          CA_3  \\\n",
       "count  29644.000000  59454.000000  62969.000000  62969.000000  62969.000000   \n",
       "mean      67.181892     81.046692     31.961918     15.926504      7.937985   \n",
       "std       22.770638     17.960987     23.197636     16.421255     10.651955   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       61.000000     76.000000     12.000000      3.000000      1.000000   \n",
       "50%       73.000000     85.000000     29.000000     10.000000      4.000000   \n",
       "75%       82.000000     93.000000     49.000000     24.000000     11.000000   \n",
       "max      100.000000    100.000000    100.000000     94.000000     89.000000   \n",
       "\n",
       "               CA_4        Height        Weight  \n",
       "count  62969.000000  65535.000000  65535.000000  \n",
       "mean       7.945910    167.077134     70.074922  \n",
       "std       10.654228     10.138942     17.785183  \n",
       "min        0.000000    150.000000     40.000000  \n",
       "25%        1.000000    158.000000     55.000000  \n",
       "50%        4.000000    167.000000     70.000000  \n",
       "75%       11.000000    176.000000     85.000000  \n",
       "max       87.000000    184.000000    100.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.describe() the function shows us the different values of the statistical functions applied to the data frame.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell I am a new columns which will contain either pass or fail\n",
    "abc=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    if(data.iloc[i,3])=='ReApp' or (data.iloc[i,3])=='FAIL' or (data.iloc[i,3])=='F' or (data.iloc[i,3])=='E':\n",
    "        abc.append(str('Fail'))\n",
    "    else:\n",
    "        abc.append(str('Passed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A        14184\n",
       "B+       12924\n",
       "A+       10946\n",
       "B         7163\n",
       "C         5710\n",
       "O         4701\n",
       "E         4378\n",
       "F         3338\n",
       "D         1674\n",
       "M          276\n",
       "I          101\n",
       "PASS        64\n",
       "R           52\n",
       "ReApp       15\n",
       "FAIL         6\n",
       "S            3\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #We are Importing the labelencoder from the sklearn.preprocessing \n",
    "label_encoder=LabelEncoder()                   #We are just creating a variable for the function\n",
    "label_encoder.fit(abc)                         #we are fitting the label encoder on our result list\n",
    "abc=label_encoder.transform(abc)               #we are tranforming the list and storing it \n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(abc,columns=['Result'])#This line Converts the abc list into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57798\n",
       "0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([data,df1],axis=1)  #In this line, we concting two DataFrame i.e the data and justly created result DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=df[df['MHRDName']=='Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 23)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38833</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38834</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ11</td>\n",
       "      <td>E</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38835</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ245</td>\n",
       "      <td>E</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38836</td>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ246</td>\n",
       "      <td>B+</td>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40904</td>\n",
       "      <td>418192</td>\n",
       "      <td>10373776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>O</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152</td>\n",
       "      <td>74</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "38833  418192   9875776   XHQ10     F     0.0     NaN      NaN     84.0   \n",
       "38834  418192   9875776   XHQ11     E    77.0     NaN      0.0      NaN   \n",
       "38835  418192   9875776  XHQ245     E    72.0    15.0     12.0      NaN   \n",
       "38836  418192   9875776  XHQ246    B+    72.0    28.0     62.0      NaN   \n",
       "40904  418192  10373776   XHQ10     O    83.0     NaN      NaN     90.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "38833         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38834        94.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38835        98.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38836        93.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "40904         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "\n",
       "       CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "38833   0.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38834   4.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38835   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38836   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "40904   0.0     152      74      Hostler      North  Female  Regional   \n",
       "\n",
       "      CourseType ProgramType Result  \n",
       "38833     Theory          UG      0  \n",
       "38834     Theory          UG      0  \n",
       "38835     Theory          UG      0  \n",
       "38836     Theory          UG      1  \n",
       "40904     Theory          UG      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\pandas\\core\\frame.py:4102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "validation.drop(cols,axis=1,inplace=True)\n",
    "validation_x=validation.drop(['Result'],axis=1)\n",
    "validation_y=validation['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "df=df.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100         2566\n",
       "MTT_50        27121\n",
       "ETT_100       25836\n",
       "ETP_100       35891\n",
       "Course_Att     6081\n",
       "CA_1           2566\n",
       "CA_2           2566\n",
       "CA_3           2566\n",
       "CA_4           2566\n",
       "Result            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "im=SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data=im.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns\n",
    "df=pd.DataFrame(imputed_data,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['CA_100']=df['CA_100'].astype(float)\n",
    "# df['MTT_50']=df['MTT_50'].astype(float)\n",
    "# df['ETT_100']=df['ETT_100'].astype(float)\n",
    "# df['Course_Att']=df['Course_Att'].astype(float)\n",
    "# df['Result']=df['Result'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the below cell we are removing the rows which consists course as practical.  Why are we Deleting ?\n",
    "we are deleting because the data we have to predict i.e Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering) is a theory one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols=['ETP_100','CA_1','CA_2','CA_3','CA_4','Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "#       ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "# train_data=df.drop(cols,axis=1)\n",
    "train_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data.isnull().sum(axis=1)<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    57798\n",
       "0.0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=train_data.dropna()\n",
    "arr=result['Result']\n",
    "result=result.drop(['Result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=ss.fit_transform(result)\n",
    "abc.reshape(-1,1)\n",
    "abc.shape\n",
    "cols=result.columns\n",
    "result=pd.DataFrame(abc,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>1.425380e+00</td>\n",
       "      <td>1.674976e+00</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>0.406454</td>\n",
       "      <td>3.974745e-01</td>\n",
       "      <td>1.806207</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-0.760849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>2.310066e+00</td>\n",
       "      <td>7.241599e-01</td>\n",
       "      <td>1.163488</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>2.376473e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-0.665095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>8.666940e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>6.122992e-01</td>\n",
       "      <td>0.641104</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>1.936696e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-4.729303e-01</td>\n",
       "      <td>-0.282081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3.044457e-16</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.967594</td>\n",
       "      <td>-0.411912</td>\n",
       "      <td>-1.562403e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.506435e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>8.724513e-01</td>\n",
       "      <td>8.919510e-01</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>4.414522e-01</td>\n",
       "      <td>0.625822</td>\n",
       "      <td>-5.687043e-01</td>\n",
       "      <td>0.866961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CA_100        MTT_50       ETT_100   ETP_100  Course_Att  \\\n",
       "0  9.952347e-01  1.425380e+00  1.674976e+00  1.424680    0.406454   \n",
       "1  9.952347e-01  2.310066e+00  7.241599e-01  1.163488    0.055725   \n",
       "2  8.666940e-01  3.195225e-01  6.122992e-01  0.641104   -0.295003   \n",
       "3  3.044457e-16  3.928796e-16 -3.974090e-16  0.967594   -0.411912   \n",
       "4  9.952347e-01  8.724513e-01  8.919510e-01  1.424680   -0.295003   \n",
       "\n",
       "           CA_1      CA_2          CA_3      CA_4  \n",
       "0  3.974745e-01  1.806207 -6.644782e-01 -0.760849  \n",
       "1  2.376473e+00 -0.989443 -7.602521e-01 -0.665095  \n",
       "2  1.936696e+00 -0.989443 -4.729303e-01 -0.282081  \n",
       "3 -1.562403e-16  0.000000 -8.506435e-17  0.000000  \n",
       "4  4.414522e-01  0.625822 -5.687043e-01  0.866961  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>1.745519e-15</td>\n",
       "      <td>-1.782266e-15</td>\n",
       "      <td>-2.145025e-16</td>\n",
       "      <td>6.155271e-16</td>\n",
       "      <td>-3.926856e-15</td>\n",
       "      <td>9.516526e-16</td>\n",
       "      <td>-7.370434e-16</td>\n",
       "      <td>-6.777959e-16</td>\n",
       "      <td>-1.110574e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-2.732447e+00</td>\n",
       "      <td>-2.887465e+00</td>\n",
       "      <td>-2.911313e+00</td>\n",
       "      <td>-4.386848e+00</td>\n",
       "      <td>-4.737561e+00</td>\n",
       "      <td>-1.405613e+00</td>\n",
       "      <td>-9.894431e-01</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-7.608488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-4.187137e-01</td>\n",
       "      <td>-1.228206e-01</td>\n",
       "      <td>-2.934656e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.365482e-01</td>\n",
       "      <td>-8.339024e-01</td>\n",
       "      <td>-8.030664e-01</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-6.650953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>1.811432e-01</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.141801e-01</td>\n",
       "      <td>-4.230298e-02</td>\n",
       "      <td>-3.060618e-01</td>\n",
       "      <td>-3.771564e-01</td>\n",
       "      <td>-3.778347e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>6.953063e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>4.445082e-01</td>\n",
       "      <td>2.493151e-01</td>\n",
       "      <td>6.402726e-01</td>\n",
       "      <td>7.053187e-01</td>\n",
       "      <td>5.015706e-01</td>\n",
       "      <td>2.932612e-01</td>\n",
       "      <td>2.924399e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.552245e+00</td>\n",
       "      <td>2.641824e+00</td>\n",
       "      <td>2.681722e+00</td>\n",
       "      <td>2.142959e+00</td>\n",
       "      <td>1.107910e+00</td>\n",
       "      <td>2.992162e+00</td>\n",
       "      <td>4.850360e+00</td>\n",
       "      <td>7.763629e+00</td>\n",
       "      <td>7.569707e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CA_100        MTT_50       ETT_100       ETP_100    Course_Att  \\\n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04   \n",
       "mean   1.745519e-15 -1.782266e-15 -2.145025e-16  6.155271e-16 -3.926856e-15   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.732447e+00 -2.887465e+00 -2.911313e+00 -4.386848e+00 -4.737561e+00   \n",
       "25%   -4.187137e-01 -1.228206e-01 -2.934656e-03  0.000000e+00 -2.365482e-01   \n",
       "50%    1.811432e-01  3.928796e-16 -3.974090e-16  0.000000e+00  1.141801e-01   \n",
       "75%    6.953063e-01  3.195225e-01  4.445082e-01  2.493151e-01  6.402726e-01   \n",
       "max    1.552245e+00  2.641824e+00  2.681722e+00  2.142959e+00  1.107910e+00   \n",
       "\n",
       "               CA_1          CA_2          CA_3          CA_4  \n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  \n",
       "mean   9.516526e-16 -7.370434e-16 -6.777959e-16 -1.110574e-15  \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  \n",
       "min   -1.405613e+00 -9.894431e-01 -7.602521e-01 -7.608488e-01  \n",
       "25%   -8.339024e-01 -8.030664e-01 -6.644782e-01 -6.650953e-01  \n",
       "50%   -4.230298e-02 -3.060618e-01 -3.771564e-01 -3.778347e-01  \n",
       "75%    7.053187e-01  5.015706e-01  2.932612e-01  2.924399e-01  \n",
       "max    2.992162e+00  4.850360e+00  7.763629e+00  7.569707e+00  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=result\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52428, 9)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr1=LogisticRegression(solver='liblinear',C=0.0007)\n",
    "lr2=LogisticRegression(solver='saga',C=0.0007)\n",
    "lr3=LogisticRegression(solver='liblinear',C=0.02)\n",
    "lr4=LogisticRegression(solver='saga',C=0.02)\n",
    "lr5=LogisticRegression(solver='liblinear',C=1)\n",
    "lr6=LogisticRegression(solver='saga',C=1)\n",
    "lr7=LogisticRegression(solver='liblinear',C=3)\n",
    "lr8=LogisticRegression(solver='saga',C=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr1.fit(x_train,y_train)\n",
    "lr2.fit(x_train,y_train)\n",
    "lr3.fit(x_train,y_train)\n",
    "lr4.fit(x_train,y_train)\n",
    "lr5.fit(x_train,y_train)\n",
    "lr6.fit(x_train,y_train)\n",
    "lr7.fit(x_train,y_train)\n",
    "lr8.fit(x_train,y_train)\n",
    "y_pred1=lr1.predict(x_test)\n",
    "y_pred2=lr2.predict(x_test)\n",
    "y_pred3=lr3.predict(x_test)\n",
    "y_pred4=lr4.predict(x_test)\n",
    "y_pred5=lr5.predict(x_test)\n",
    "y_pred6=lr6.predict(x_test)\n",
    "y_pred7=lr7.predict(x_test)\n",
    "y_pred8=lr8.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716945143816281\n",
      "0.9614709697108416\n",
      "0.974517433432517\n",
      "0.9742885481040665\n",
      "0.9748226138704509\n",
      "0.9748226138704509\n",
      "0.9750514991989013\n",
      "0.9750514991989013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(accuracy_score(y_test,y_pred3))\n",
    "print(accuracy_score(y_test,y_pred4))\n",
    "print(accuracy_score(y_test,y_pred5))\n",
    "print(accuracy_score(y_test,y_pred6))\n",
    "print(accuracy_score(y_test,y_pred7))\n",
    "print(accuracy_score(y_test,y_pred8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.85      0.89      1514\n",
      "         1.0       0.98      0.99      0.99     11593\n",
      "\n",
      "    accuracy                           0.97     13107\n",
      "   macro avg       0.95      0.92      0.94     13107\n",
      "weighted avg       0.97      0.97      0.97     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x_train,y_train)\n",
    "y_pred=dt.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9798580910963607"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1400,   150],\n",
       "       [  114, 11443]], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.92      0.91      1514\n",
      "         1.0       0.99      0.99      0.99     11593\n",
      "\n",
      "    accuracy                           0.98     13107\n",
      "   macro avg       0.95      0.96      0.95     13107\n",
      "weighted avg       0.98      0.98      0.98     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>38833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38834</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38835</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38836</td>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40904</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40905</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40906</td>\n",
       "      <td>95.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40907</td>\n",
       "      <td>97.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA_100  MTT_50  ETT_100  ETP_100  Course_Att  CA_1  CA_2  CA_3  CA_4\n",
       "38833     0.0     NaN      NaN     84.0         NaN   0.0   0.0   0.0   0.0\n",
       "38834    77.0     NaN      0.0      NaN        94.0  29.0  44.0   0.0   4.0\n",
       "38835    72.0    15.0     12.0      NaN        98.0  53.0   3.0  15.0   1.0\n",
       "38836    72.0    28.0     62.0      NaN        93.0  55.0  14.0   2.0   1.0\n",
       "40904    83.0     NaN      NaN     90.0         NaN  68.0   9.0   6.0   0.0\n",
       "40905    87.0     NaN     60.0      NaN        84.0  73.0   7.0   1.0   6.0\n",
       "40906    95.0    43.0     83.0      NaN        78.0  42.0  18.0  20.0  15.0\n",
       "40907    97.0    48.0     73.0      NaN        83.0  58.0   4.0  11.0  24.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 33.5       , 48.33333333, 84.        , 88.33333333,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [77.        , 33.5       ,  0.        , 87.        , 94.        ,\n",
       "        29.        , 44.        ,  0.        ,  4.        ],\n",
       "       [72.        , 15.        , 12.        , 87.        , 98.        ,\n",
       "        53.        ,  3.        , 15.        ,  1.        ],\n",
       "       [72.        , 28.        , 62.        , 87.        , 93.        ,\n",
       "        55.        , 14.        ,  2.        ,  1.        ],\n",
       "       [83.        , 33.5       , 48.33333333, 90.        , 88.33333333,\n",
       "        68.        ,  9.        ,  6.        ,  0.        ],\n",
       "       [87.        , 33.5       , 60.        , 87.        , 84.        ,\n",
       "        73.        ,  7.        ,  1.        ,  6.        ],\n",
       "       [95.        , 43.        , 83.        , 87.        , 78.        ,\n",
       "        42.        , 18.        , 20.        , 15.        ],\n",
       "       [97.        , 48.        , 73.        , 87.        , 83.        ,\n",
       "        58.        ,  4.        , 11.        , 24.        ]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x=im.fit_transform(validation_x)\n",
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x=ss.fit_transform(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dt.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38833    0\n",
       "38834    0\n",
       "38835    0\n",
       "38836    1\n",
       "40904    1\n",
       "40905    1\n",
       "40906    1\n",
       "40907    1\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validation_y,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying with the ANN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0408 15:31:31.274833 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_dim=9, activation=\"relu\", units=8, kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "W0408 15:31:31.298769 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0408 15:31:31.302760 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=6, kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=3, kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n",
      "  \n",
      "W0408 15:31:31.426430 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0408 15:31:31.477294 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0408 15:31:31.490257 17156 deprecation.py:323] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 80        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 3)                 21        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier=Sequential()\n",
    "# 1st Convolutional Layer\n",
    "classifier.add(Dense(output_dim=8,init='uniform',input_dim=9,activation='relu'))\n",
    "classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
    "classifier.add(Dense(output_dim=3,init='uniform',activation='relu'))\n",
    "\n",
    "#output layer\n",
    "classifier.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:1: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "W0408 15:31:32.789875 17156 deprecation_wrapper.py:119] From C:\\Users\\Shiva Chandra\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 47185 samples, validate on 5243 samples\n",
      "Epoch 1/10\n",
      "47185/47185 [==============================] - 10s 221us/step - loss: 0.1335 - acc: 0.9662 - val_loss: 0.0666 - val_acc: 0.9786\n",
      "Epoch 2/10\n",
      "47185/47185 [==============================] - 9s 185us/step - loss: 0.0623 - acc: 0.9795 - val_loss: 0.0634 - val_acc: 0.9790\n",
      "Epoch 3/10\n",
      "47185/47185 [==============================] - 9s 187us/step - loss: 0.0607 - acc: 0.9798 - val_loss: 0.0622 - val_acc: 0.9779\n",
      "Epoch 4/10\n",
      "47185/47185 [==============================] - 9s 199us/step - loss: 0.0599 - acc: 0.9800 - val_loss: 0.0616 - val_acc: 0.9790\n",
      "Epoch 5/10\n",
      "47185/47185 [==============================] - 9s 198us/step - loss: 0.0596 - acc: 0.9798 - val_loss: 0.0617 - val_acc: 0.9784\n",
      "Epoch 6/10\n",
      "47185/47185 [==============================] - 10s 217us/step - loss: 0.0589 - acc: 0.9800 - val_loss: 0.0610 - val_acc: 0.9788\n",
      "Epoch 7/10\n",
      "47185/47185 [==============================] - 8s 170us/step - loss: 0.0583 - acc: 0.9798 - val_loss: 0.0602 - val_acc: 0.9792\n",
      "Epoch 8/10\n",
      "47185/47185 [==============================] - 9s 190us/step - loss: 0.0568 - acc: 0.9810 - val_loss: 0.0577 - val_acc: 0.9817\n",
      "Epoch 9/10\n",
      "47185/47185 [==============================] - 9s 186us/step - loss: 0.0546 - acc: 0.9825 - val_loss: 0.0567 - val_acc: 0.9817\n",
      "Epoch 10/10\n",
      "47185/47185 [==============================] - 7s 155us/step - loss: 0.0536 - acc: 0.9827 - val_loss: 0.0563 - val_acc: 0.9828\n"
     ]
    }
   ],
   "source": [
    "history=classifier.fit(x_train,y_train,verbose=1,validation_split=0.1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       ...,\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982604715037766\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs of Accuracy and Loss of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(validation_x)\n",
    "predictions=(predictions>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.875\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(validation_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 1],\n",
       "       [0, 5]], dtype=int64)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm=confusion_matrix(validation_y,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x20da9553b70>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pylab as pl\n",
    "pl.matshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
