{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying weather a student will Pass a course or Not.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying in the course -> Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This Course is a Theory type and in this dataset, we have only 8 Rows, so I am training my models on the entire data except for this course and try to predict (Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np       #Importing Numerical Python(Numpy)\n",
    "import pandas as pd      #Importing Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the dataset using read_csv function in pandas library\n",
    "data=pd.read_csv(r'C:\\Users\\Shiva Chandra\\Desktop\\ML\\Project Sem 2 Year 3\\DATA-FINAL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.shape gives us the no.of rows and columns the dataset consists of.\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY1</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY147</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY148</td>\n",
       "      <td>B+</td>\n",
       "      <td>84.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY2</td>\n",
       "      <td>A+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Practical</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>318192</td>\n",
       "      <td>1101776</td>\n",
       "      <td>KVY3</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>181</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Termid  Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "0  318192  1101776    KVY1     O    87.0    39.0     82.0     89.0   \n",
       "1  318192  1101776  KVY147    A+    87.0    47.0     65.0     85.0   \n",
       "2  318192  1101776  KVY148    B+    84.0    29.0     63.0     77.0   \n",
       "3  318192  1101776    KVY2    A+     NaN     NaN      NaN     82.0   \n",
       "4  318192  1101776    KVY3    A+    87.0    34.0     68.0     89.0   \n",
       "\n",
       "   Course_Att                                     MHRDName  ...  CA_3  CA_4  \\\n",
       "0        88.0  Bachelor of Science (Honours) (Agriculture)  ...   1.0   0.0   \n",
       "1        82.0  Bachelor of Science (Honours) (Agriculture)  ...   0.0   1.0   \n",
       "2        76.0  Bachelor of Science (Honours) (Agriculture)  ...   3.0   5.0   \n",
       "3        74.0  Bachelor of Science (Honours) (Agriculture)  ...   NaN   NaN   \n",
       "4        76.0  Bachelor of Science (Honours) (Agriculture)  ...   2.0  17.0   \n",
       "\n",
       "   Height  Weight  ScholarType  Direction  Gender Medium CourseType  \\\n",
       "0     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "1     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "2     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "3     181      65      Hostler      North  Female  Hindi  Practical   \n",
       "4     181      65      Hostler      North  Female  Hindi     Theory   \n",
       "\n",
       "  ProgramType  \n",
       "0          UG  \n",
       "1          UG  \n",
       "2          UG  \n",
       "3          UG  \n",
       "4          UG  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.head gives us the Top 5 rows of the DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Termid', 'Regd No', 'Course', 'Grade', 'CA_100', 'MTT_50', 'ETT_100',\n",
       "       'ETP_100', 'Course_Att', 'MHRDName', 'CA_1', 'CA_2', 'CA_3', 'CA_4',\n",
       "       'Height', 'Weight', 'ScholarType', 'Direction', 'Gender', 'Medium',\n",
       "       'CourseType', 'ProgramType'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.columns gives us the name of the columns present in the DataFrame\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell, I am trying to get how many i.e no.of uniques courses.\n",
    "data['MHRDName'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same as the above cell but with the program type column\n",
    "data['ProgramType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UG    64635\n",
       "PG      900\n",
       "Name: ProgramType, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By the above cell we Know that there are two type of programs, now in this cell we are trying the how many no.of a program \n",
    "#repeating\n",
    "data['ProgramType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we trying to get unique grades\n",
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CourseType'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Termid             0\n",
       "Regd No            0\n",
       "Course             0\n",
       "Grade              0\n",
       "CA_100          2566\n",
       "MTT_50         27121\n",
       "ETT_100        25836\n",
       "ETP_100        35891\n",
       "Course_Att      6081\n",
       "MHRDName           0\n",
       "CA_1            2566\n",
       "CA_2            2566\n",
       "CA_3            2566\n",
       "CA_4            2566\n",
       "Height             0\n",
       "Weight             0\n",
       "ScholarType        0\n",
       "Direction          0\n",
       "Gender             0\n",
       "Medium             0\n",
       "CourseType         0\n",
       "ProgramType        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this cell we are going to get the no.of null values in each column \n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>518192</td>\n",
       "      <td>1103776</td>\n",
       "      <td>OLZ7</td>\n",
       "      <td>A+</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Computer Applications (2 Year progra...</td>\n",
       "      <td>...</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>66</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>418192</td>\n",
       "      <td>1104776</td>\n",
       "      <td>XPH10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Mechanical Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>163</td>\n",
       "      <td>67</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>518192</td>\n",
       "      <td>1105776</td>\n",
       "      <td>KYI12</td>\n",
       "      <td>A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Bachelor of Technology - Master of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>155</td>\n",
       "      <td>75</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>318192</td>\n",
       "      <td>1119776</td>\n",
       "      <td>VJS87</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>182</td>\n",
       "      <td>97</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>518192</td>\n",
       "      <td>1121776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>B+</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>182</td>\n",
       "      <td>69</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>518192</td>\n",
       "      <td>1121776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>A</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182</td>\n",
       "      <td>69</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>518192</td>\n",
       "      <td>1123776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>96</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>518192</td>\n",
       "      <td>1123776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180</td>\n",
       "      <td>96</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>518192</td>\n",
       "      <td>1124776</td>\n",
       "      <td>IAD106</td>\n",
       "      <td>A</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Information Technology)</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>169</td>\n",
       "      <td>54</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>518192</td>\n",
       "      <td>1125776</td>\n",
       "      <td>UVV108</td>\n",
       "      <td>R</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Bachelor of Technology - Master of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>183</td>\n",
       "      <td>55</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>518192</td>\n",
       "      <td>1129776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>A+</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>170</td>\n",
       "      <td>86</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>518192</td>\n",
       "      <td>1129776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>A</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170</td>\n",
       "      <td>86</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>518192</td>\n",
       "      <td>1130776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>A</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>518192</td>\n",
       "      <td>1130776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>B+</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170</td>\n",
       "      <td>50</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>518192</td>\n",
       "      <td>1131776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>A</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>171</td>\n",
       "      <td>52</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>518192</td>\n",
       "      <td>1131776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>A</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>171</td>\n",
       "      <td>52</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>518192</td>\n",
       "      <td>1158776</td>\n",
       "      <td>UDK100</td>\n",
       "      <td>A+</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>173</td>\n",
       "      <td>88</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>518192</td>\n",
       "      <td>1158776</td>\n",
       "      <td>UDK101</td>\n",
       "      <td>B+</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>173</td>\n",
       "      <td>88</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>318192</td>\n",
       "      <td>1159776</td>\n",
       "      <td>QDN87</td>\n",
       "      <td>O</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>176</td>\n",
       "      <td>54</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>418192</td>\n",
       "      <td>1164776</td>\n",
       "      <td>XPH10</td>\n",
       "      <td>A+</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Mechanical Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>173</td>\n",
       "      <td>44</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>318192</td>\n",
       "      <td>1171776</td>\n",
       "      <td>JFU1069</td>\n",
       "      <td>A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Mathematics)</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>154</td>\n",
       "      <td>51</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>418192</td>\n",
       "      <td>1180776</td>\n",
       "      <td>KVY225</td>\n",
       "      <td>O</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>177</td>\n",
       "      <td>97</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>418192</td>\n",
       "      <td>1180776</td>\n",
       "      <td>KVY226</td>\n",
       "      <td>A</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177</td>\n",
       "      <td>97</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>218192</td>\n",
       "      <td>1183776</td>\n",
       "      <td>VKB234</td>\n",
       "      <td>A+</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Science (Food Science and Technology)</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>160</td>\n",
       "      <td>45</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>318192</td>\n",
       "      <td>1185776</td>\n",
       "      <td>QDN87</td>\n",
       "      <td>A+</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>165</td>\n",
       "      <td>74</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>318192</td>\n",
       "      <td>1186776</td>\n",
       "      <td>QDN87</td>\n",
       "      <td>A</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>179</td>\n",
       "      <td>77</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>318192</td>\n",
       "      <td>1189776</td>\n",
       "      <td>QDN87</td>\n",
       "      <td>O</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>184</td>\n",
       "      <td>99</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>418192</td>\n",
       "      <td>1190776</td>\n",
       "      <td>XPH10</td>\n",
       "      <td>B+</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Mechanical Engineering</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>171</td>\n",
       "      <td>91</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>218192</td>\n",
       "      <td>1191776</td>\n",
       "      <td>OLZ7</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Computer Applications (2 Year progra...</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>173</td>\n",
       "      <td>64</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>218192</td>\n",
       "      <td>1193776</td>\n",
       "      <td>OLZ7</td>\n",
       "      <td>A+</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Computer Applications (2 Year progra...</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>160</td>\n",
       "      <td>76</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64800</th>\n",
       "      <td>318192</td>\n",
       "      <td>15295776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>A+</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>161</td>\n",
       "      <td>62</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64810</th>\n",
       "      <td>318192</td>\n",
       "      <td>15296776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64818</th>\n",
       "      <td>318192</td>\n",
       "      <td>15297776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>B+</td>\n",
       "      <td>66.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>176</td>\n",
       "      <td>71</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64838</th>\n",
       "      <td>318192</td>\n",
       "      <td>15300776</td>\n",
       "      <td>AUK538</td>\n",
       "      <td>A</td>\n",
       "      <td>76.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Civil Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>98</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64866</th>\n",
       "      <td>318192</td>\n",
       "      <td>15305776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>154</td>\n",
       "      <td>61</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64904</th>\n",
       "      <td>318192</td>\n",
       "      <td>15313776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>B+</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>178</td>\n",
       "      <td>52</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64912</th>\n",
       "      <td>318192</td>\n",
       "      <td>15314776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>O</td>\n",
       "      <td>92.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>160</td>\n",
       "      <td>48</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64934</th>\n",
       "      <td>118192</td>\n",
       "      <td>15318776</td>\n",
       "      <td>IRJ2210</td>\n",
       "      <td>A+</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Science (Chemistry)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>99</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64967</th>\n",
       "      <td>318192</td>\n",
       "      <td>15323776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>180</td>\n",
       "      <td>64</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64973</th>\n",
       "      <td>318192</td>\n",
       "      <td>15324776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>156</td>\n",
       "      <td>63</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65027</th>\n",
       "      <td>318192</td>\n",
       "      <td>15330776</td>\n",
       "      <td>UDK604</td>\n",
       "      <td>B+</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Architecture</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>170</td>\n",
       "      <td>62</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65058</th>\n",
       "      <td>118192</td>\n",
       "      <td>15341776</td>\n",
       "      <td>RRP1399</td>\n",
       "      <td>A+</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Master of Technology (Computer Science and Eng...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>170</td>\n",
       "      <td>96</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>PG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65134</th>\n",
       "      <td>318192</td>\n",
       "      <td>15352776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>180</td>\n",
       "      <td>93</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65175</th>\n",
       "      <td>318192</td>\n",
       "      <td>15358776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>151</td>\n",
       "      <td>51</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65184</th>\n",
       "      <td>318192</td>\n",
       "      <td>15359776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>48.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>167</td>\n",
       "      <td>71</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65217</th>\n",
       "      <td>318192</td>\n",
       "      <td>15365776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>86.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>64</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65225</th>\n",
       "      <td>318192</td>\n",
       "      <td>15366776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>A</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>164</td>\n",
       "      <td>65</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65228</th>\n",
       "      <td>518192</td>\n",
       "      <td>15368776</td>\n",
       "      <td>OEK1183</td>\n",
       "      <td>A</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Integrated Bachelor of Technology - Master of ...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>155</td>\n",
       "      <td>100</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65256</th>\n",
       "      <td>418192</td>\n",
       "      <td>15377776</td>\n",
       "      <td>FKD267</td>\n",
       "      <td>A+</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Electrical Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>85</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65259</th>\n",
       "      <td>418192</td>\n",
       "      <td>15379776</td>\n",
       "      <td>AUK538</td>\n",
       "      <td>A+</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>72.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Civil Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>180</td>\n",
       "      <td>61</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65279</th>\n",
       "      <td>318192</td>\n",
       "      <td>15381776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>A+</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>18.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>154</td>\n",
       "      <td>69</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65287</th>\n",
       "      <td>318192</td>\n",
       "      <td>15382776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>A</td>\n",
       "      <td>65.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>171</td>\n",
       "      <td>55</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65323</th>\n",
       "      <td>318192</td>\n",
       "      <td>15387776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>A+</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>74.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>169</td>\n",
       "      <td>76</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65331</th>\n",
       "      <td>318192</td>\n",
       "      <td>15388776</td>\n",
       "      <td>BIE87</td>\n",
       "      <td>O</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>174</td>\n",
       "      <td>52</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>South</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65343</th>\n",
       "      <td>318192</td>\n",
       "      <td>15390776</td>\n",
       "      <td>GDM1230</td>\n",
       "      <td>A+</td>\n",
       "      <td>89.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Physics)</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>173</td>\n",
       "      <td>48</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Female</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65351</th>\n",
       "      <td>318192</td>\n",
       "      <td>15391776</td>\n",
       "      <td>TGE87</td>\n",
       "      <td>O</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology in Computer Science and...</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>169</td>\n",
       "      <td>96</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65418</th>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX225</td>\n",
       "      <td>O</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65419</th>\n",
       "      <td>418192</td>\n",
       "      <td>15408776</td>\n",
       "      <td>OXX226</td>\n",
       "      <td>A+</td>\n",
       "      <td>88.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Science (Honours) (Agriculture)</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>173</td>\n",
       "      <td>86</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65459</th>\n",
       "      <td>318192</td>\n",
       "      <td>15416776</td>\n",
       "      <td>AUK538</td>\n",
       "      <td>B+</td>\n",
       "      <td>57.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>64.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Civil Engineering)</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150</td>\n",
       "      <td>73</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65467</th>\n",
       "      <td>318192</td>\n",
       "      <td>15417776</td>\n",
       "      <td>CFB87</td>\n",
       "      <td>O</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bachelor of Technology (Computer Science and E...</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>167</td>\n",
       "      <td>47</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>East</td>\n",
       "      <td>Male</td>\n",
       "      <td>English</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4480 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No   Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "12     518192   1103776     OLZ7    A+    87.0     NaN      NaN     69.0   \n",
       "13     418192   1104776    XPH10     F     0.0     NaN      NaN      0.0   \n",
       "17     518192   1105776    KYI12     A    89.0     NaN      NaN     64.0   \n",
       "95     318192   1119776    VJS87    B+    57.0     NaN      NaN     62.0   \n",
       "113    518192   1121776   UDK100    B+    80.0     NaN      NaN     64.0   \n",
       "114    518192   1121776   UDK101     A    78.0     NaN      NaN     75.0   \n",
       "115    518192   1123776   UDK100     F     0.0     NaN      NaN      0.0   \n",
       "116    518192   1123776   UDK101     F     0.0     NaN      NaN      0.0   \n",
       "120    518192   1124776   IAD106     A    86.0     NaN      NaN     76.0   \n",
       "125    518192   1125776   UVV108     R    70.0     NaN      NaN     28.0   \n",
       "145    518192   1129776   UDK100    A+    83.0     NaN      NaN     78.0   \n",
       "146    518192   1129776   UDK101     A    83.0     NaN      NaN     76.0   \n",
       "147    518192   1130776   UDK100     A    73.0     NaN      NaN     75.0   \n",
       "148    518192   1130776   UDK101    B+    80.0     NaN      NaN     69.0   \n",
       "149    518192   1131776   UDK100     A    78.0     NaN      NaN     76.0   \n",
       "150    518192   1131776   UDK101     A    80.0     NaN      NaN     75.0   \n",
       "231    518192   1158776   UDK100    A+    79.0     NaN      NaN     77.0   \n",
       "232    518192   1158776   UDK101    B+    75.0     NaN      NaN     65.0   \n",
       "238    318192   1159776    QDN87     O    77.0     NaN      NaN     88.0   \n",
       "261    418192   1164776    XPH10    A+    95.0     NaN      NaN     74.0   \n",
       "276    318192   1171776  JFU1069     A    89.0     NaN      NaN     71.0   \n",
       "321    418192   1180776   KVY225     O    91.0     NaN      NaN     72.0   \n",
       "322    418192   1180776   KVY226     A    89.0     NaN      NaN     73.0   \n",
       "327    218192   1183776   VKB234    A+    84.0     NaN      NaN     84.0   \n",
       "333    318192   1185776    QDN87    A+    75.0     NaN      NaN     75.0   \n",
       "341    318192   1186776    QDN87     A    78.0     NaN      NaN     70.0   \n",
       "360    318192   1189776    QDN87     O    82.0     NaN      NaN     86.0   \n",
       "363    418192   1190776    XPH10    B+    64.0     NaN      NaN     61.0   \n",
       "367    218192   1191776     OLZ7     O    87.0     NaN      NaN     87.0   \n",
       "368    218192   1193776     OLZ7    A+    82.0     NaN      NaN     82.0   \n",
       "...       ...       ...      ...   ...     ...     ...      ...      ...   \n",
       "64800  318192  15295776    TGE87    A+    80.0     NaN      NaN     80.0   \n",
       "64810  318192  15296776    TGE87     O    84.0     NaN      NaN     89.0   \n",
       "64818  318192  15297776    BIE87    B+    66.0     NaN      NaN     76.0   \n",
       "64838  318192  15300776   AUK538     A    76.0     NaN      NaN     71.0   \n",
       "64866  318192  15305776    CFB87     O    84.0     NaN      NaN     84.0   \n",
       "64904  318192  15313776    BIE87    B+    70.0     NaN      NaN     70.0   \n",
       "64912  318192  15314776    BIE87     O    92.0     NaN      NaN     96.0   \n",
       "64934  118192  15318776  IRJ2210    A+    85.0     NaN      NaN     86.0   \n",
       "64967  318192  15323776    TGE87     O    88.0     NaN      NaN     89.0   \n",
       "64973  318192  15324776    CFB87     O    73.0     NaN      NaN     88.0   \n",
       "65027  318192  15330776   UDK604    B+    73.0     NaN      NaN     63.0   \n",
       "65058  118192  15341776  RRP1399    A+    88.0     NaN      NaN     82.0   \n",
       "65134  318192  15352776    TGE87     O    84.0     NaN      NaN     82.0   \n",
       "65175  318192  15358776    TGE87     O    82.0     NaN      NaN     85.0   \n",
       "65184  318192  15359776    CFB87     O    85.0     NaN      NaN     80.0   \n",
       "65217  318192  15365776    TGE87     O    85.0     NaN      NaN     86.0   \n",
       "65225  318192  15366776    BIE87     A    73.0     NaN      NaN     73.0   \n",
       "65228  518192  15368776  OEK1183     A    91.0     NaN      NaN     64.0   \n",
       "65256  418192  15377776   FKD267    A+    77.0     NaN      NaN     79.0   \n",
       "65259  418192  15379776   AUK538    A+    79.0     NaN      NaN     72.0   \n",
       "65279  318192  15381776    BIE87    A+    77.0     NaN      NaN     80.0   \n",
       "65287  318192  15382776    BIE87     A    65.0     NaN      NaN     80.0   \n",
       "65323  318192  15387776    TGE87    A+    77.0     NaN      NaN     74.0   \n",
       "65331  318192  15388776    BIE87     O    83.0     NaN      NaN     77.0   \n",
       "65343  318192  15390776  GDM1230    A+    89.0     NaN      NaN     82.0   \n",
       "65351  318192  15391776    TGE87     O    88.0     NaN      NaN     82.0   \n",
       "65418  418192  15408776   OXX225     O    87.0     NaN      NaN     81.0   \n",
       "65419  418192  15408776   OXX226    A+    88.0     NaN      NaN     87.0   \n",
       "65459  318192  15416776   AUK538    B+    57.0     NaN      NaN     64.0   \n",
       "65467  318192  15417776    CFB87     O    90.0     NaN      NaN     75.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "12            NaN  Master of Computer Applications (2 Year progra...  ...   \n",
       "13            NaN   Bachelor of Technology in Mechanical Engineering  ...   \n",
       "17            NaN  Integrated Bachelor of Technology - Master of ...  ...   \n",
       "95            NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "113           NaN                           Bachelor of Architecture  ...   \n",
       "114           NaN                           Bachelor of Architecture  ...   \n",
       "115           NaN                           Bachelor of Architecture  ...   \n",
       "116           NaN                           Bachelor of Architecture  ...   \n",
       "120           NaN    Bachelor of Technology (Information Technology)  ...   \n",
       "125           NaN  Integrated Bachelor of Technology - Master of ...  ...   \n",
       "145           NaN                           Bachelor of Architecture  ...   \n",
       "146           NaN                           Bachelor of Architecture  ...   \n",
       "147           NaN                           Bachelor of Architecture  ...   \n",
       "148           NaN                           Bachelor of Architecture  ...   \n",
       "149           NaN                           Bachelor of Architecture  ...   \n",
       "150           NaN                           Bachelor of Architecture  ...   \n",
       "231           NaN                           Bachelor of Architecture  ...   \n",
       "232           NaN                           Bachelor of Architecture  ...   \n",
       "238           NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "261           NaN   Bachelor of Technology in Mechanical Engineering  ...   \n",
       "276           NaN        Bachelor of Science (Honours) (Mathematics)  ...   \n",
       "321           NaN        Bachelor of Science (Honours) (Agriculture)  ...   \n",
       "322           NaN        Bachelor of Science (Honours) (Agriculture)  ...   \n",
       "327           NaN    Master of Science (Food Science and Technology)  ...   \n",
       "333           NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "341           NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "360           NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "363           NaN   Bachelor of Technology in Mechanical Engineering  ...   \n",
       "367           NaN  Master of Computer Applications (2 Year progra...  ...   \n",
       "368           NaN  Master of Computer Applications (2 Year progra...  ...   \n",
       "...           ...                                                ...  ...   \n",
       "64800         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64810         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64818         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64838         NaN         Bachelor of Technology (Civil Engineering)  ...   \n",
       "64866         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "64904         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64912         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64934         NaN                      Master of Science (Chemistry)  ...   \n",
       "64967         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "64973         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "65027         NaN                           Bachelor of Architecture  ...   \n",
       "65058         NaN  Master of Technology (Computer Science and Eng...  ...   \n",
       "65134         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65175         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65184         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "65217         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65225         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65228         NaN  Integrated Bachelor of Technology - Master of ...  ...   \n",
       "65256         NaN    Bachelor of Technology (Electrical Engineering)  ...   \n",
       "65259         NaN         Bachelor of Technology (Civil Engineering)  ...   \n",
       "65279         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65287         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65323         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65331         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65343         NaN            Bachelor of Science (Honours) (Physics)  ...   \n",
       "65351         NaN  Bachelor of Technology in Computer Science and...  ...   \n",
       "65418         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65419         NaN       Bachelor of Science (Honours) (Agriculture)   ...   \n",
       "65459         NaN         Bachelor of Technology (Civil Engineering)  ...   \n",
       "65467         NaN  Bachelor of Technology (Computer Science and E...  ...   \n",
       "\n",
       "       CA_3  CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "12     16.0   1.0     170      66      Hostler       West    Male  Regional   \n",
       "13      0.0   0.0     163      67  Day Scholar       East    Male   English   \n",
       "17      4.0  18.0     155      75      Hostler      North  Female  Regional   \n",
       "95     10.0   9.0     182      97  Day Scholar      South    Male     Hindi   \n",
       "113     3.0   4.0     182      69  Day Scholar      North    Male  Regional   \n",
       "114     5.0   0.0     182      69  Day Scholar      North    Male  Regional   \n",
       "115     0.0   0.0     180      96  Day Scholar      South    Male     Hindi   \n",
       "116     0.0   0.0     180      96  Day Scholar      South    Male     Hindi   \n",
       "120    11.0   5.0     169      54  Day Scholar       East    Male  Regional   \n",
       "125     5.0   3.0     183      55      Hostler      South    Male     Hindi   \n",
       "145     3.0   1.0     170      86  Day Scholar      South  Female   English   \n",
       "146     0.0   8.0     170      86  Day Scholar      South  Female   English   \n",
       "147     6.0   9.0     170      50      Hostler      South    Male   English   \n",
       "148     0.0   0.0     170      50      Hostler      South    Male   English   \n",
       "149     0.0   4.0     171      52  Day Scholar      South    Male  Regional   \n",
       "150    12.0  16.0     171      52  Day Scholar      South    Male  Regional   \n",
       "231     7.0   5.0     173      88  Day Scholar       West    Male     Hindi   \n",
       "232     0.0   1.0     173      88  Day Scholar       West    Male     Hindi   \n",
       "238     1.0   0.0     176      54      Hostler       East    Male  Regional   \n",
       "261    12.0  43.0     173      44      Hostler      South  Female  Regional   \n",
       "276     7.0  22.0     154      51  Day Scholar      North    Male   English   \n",
       "321    15.0   4.0     177      97      Hostler       East  Female   English   \n",
       "322     0.0   0.0     177      97      Hostler       East  Female   English   \n",
       "327    36.0   0.0     160      45      Hostler       West  Female  Regional   \n",
       "333     3.0   3.0     165      74      Hostler       West    Male     Hindi   \n",
       "341     0.0   1.0     179      77  Day Scholar      South    Male   English   \n",
       "360     0.0  16.0     184      99      Hostler      North    Male   English   \n",
       "363     0.0   0.0     171      91      Hostler       West  Female  Regional   \n",
       "367    11.0  51.0     173      64  Day Scholar      South  Female   English   \n",
       "368    12.0  10.0     160      76      Hostler      South  Female   English   \n",
       "...     ...   ...     ...     ...          ...        ...     ...       ...   \n",
       "64800   0.0   8.0     161      62      Hostler      North  Female   English   \n",
       "64810   2.0   5.0     180      90      Hostler      South  Female   English   \n",
       "64818   1.0   2.0     176      71      Hostler       East    Male   English   \n",
       "64838   0.0   1.0     161      98      Hostler       West    Male     Hindi   \n",
       "64866   8.0  37.0     154      61      Hostler      North    Male     Hindi   \n",
       "64904  35.0   1.0     178      52      Hostler      North    Male   English   \n",
       "64912   4.0  37.0     160      48  Day Scholar      South    Male   English   \n",
       "64934   0.0   1.0     163      99  Day Scholar      North    Male   English   \n",
       "64967   4.0   1.0     180      64      Hostler       East    Male   English   \n",
       "64973  13.0  11.0     156      63      Hostler      South    Male     Hindi   \n",
       "65027  12.0  11.0     170      62      Hostler       West    Male     Hindi   \n",
       "65058   4.0   8.0     170      96      Hostler      North  Female  Regional   \n",
       "65134   3.0  42.0     180      93      Hostler       East    Male     Hindi   \n",
       "65175  14.0   4.0     151      51      Hostler      North    Male     Hindi   \n",
       "65184  48.0  19.0     167      71  Day Scholar      North  Female     Hindi   \n",
       "65217   0.0   0.0     173      64  Day Scholar      North  Female   English   \n",
       "65225   7.0  13.0     164      65      Hostler      North    Male  Regional   \n",
       "65228   2.0   1.0     155     100  Day Scholar      North    Male  Regional   \n",
       "65256   5.0   1.0     158      85  Day Scholar       West  Female     Hindi   \n",
       "65259  52.0   6.0     180      61      Hostler      South    Male   English   \n",
       "65279  18.0  27.0     154      69  Day Scholar       West    Male     Hindi   \n",
       "65287  10.0   7.0     171      55      Hostler      South  Female     Hindi   \n",
       "65323   5.0  15.0     169      76  Day Scholar      South  Female     Hindi   \n",
       "65331   2.0  15.0     174      52      Hostler      South  Female  Regional   \n",
       "65343  20.0  31.0     173      48  Day Scholar       East  Female     Hindi   \n",
       "65351  53.0  16.0     169      96      Hostler       East    Male  Regional   \n",
       "65418   1.0   0.0     173      86      Hostler      North    Male  Regional   \n",
       "65419   7.0  38.0     173      86      Hostler      North    Male  Regional   \n",
       "65459   0.0   0.0     150      73  Day Scholar       West    Male   English   \n",
       "65467  12.0  54.0     167      47  Day Scholar       East    Male   English   \n",
       "\n",
       "      CourseType ProgramType  \n",
       "12        Theory          PG  \n",
       "13        Theory          UG  \n",
       "17        Theory          UG  \n",
       "95        Theory          UG  \n",
       "113       Theory          UG  \n",
       "114       Theory          UG  \n",
       "115       Theory          UG  \n",
       "116       Theory          UG  \n",
       "120       Theory          UG  \n",
       "125       Theory          UG  \n",
       "145       Theory          UG  \n",
       "146       Theory          UG  \n",
       "147       Theory          UG  \n",
       "148       Theory          UG  \n",
       "149       Theory          UG  \n",
       "150       Theory          UG  \n",
       "231       Theory          UG  \n",
       "232       Theory          UG  \n",
       "238       Theory          UG  \n",
       "261       Theory          UG  \n",
       "276       Theory          UG  \n",
       "321       Theory          UG  \n",
       "322       Theory          UG  \n",
       "327       Theory          PG  \n",
       "333       Theory          UG  \n",
       "341       Theory          UG  \n",
       "360       Theory          UG  \n",
       "363       Theory          UG  \n",
       "367       Theory          PG  \n",
       "368       Theory          PG  \n",
       "...          ...         ...  \n",
       "64800     Theory          UG  \n",
       "64810     Theory          UG  \n",
       "64818     Theory          UG  \n",
       "64838     Theory          UG  \n",
       "64866     Theory          UG  \n",
       "64904     Theory          UG  \n",
       "64912     Theory          UG  \n",
       "64934     Theory          PG  \n",
       "64967     Theory          UG  \n",
       "64973     Theory          UG  \n",
       "65027     Theory          UG  \n",
       "65058     Theory          PG  \n",
       "65134     Theory          UG  \n",
       "65175     Theory          UG  \n",
       "65184     Theory          UG  \n",
       "65217     Theory          UG  \n",
       "65225     Theory          UG  \n",
       "65228     Theory          UG  \n",
       "65256     Theory          UG  \n",
       "65259     Theory          UG  \n",
       "65279     Theory          UG  \n",
       "65287     Theory          UG  \n",
       "65323     Theory          UG  \n",
       "65331     Theory          UG  \n",
       "65343     Theory          UG  \n",
       "65351     Theory          UG  \n",
       "65418     Theory          UG  \n",
       "65419     Theory          UG  \n",
       "65459     Theory          UG  \n",
       "65467     Theory          UG  \n",
       "\n",
       "[4480 rows x 22 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#In this we are checking the data which have more than or equal to 3 null values in a row and the course type is not practical\n",
    "h=data[data['CourseType']!='Practical']\n",
    "h=h[h.isnull().sum(axis=1)>=3]\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>65535.000000</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>38414.000000</td>\n",
       "      <td>39699.000000</td>\n",
       "      <td>29644.000000</td>\n",
       "      <td>59454.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>62969.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>288099.682918</td>\n",
       "      <td>8.450856e+06</td>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.052470</td>\n",
       "      <td>67.181892</td>\n",
       "      <td>81.046692</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.945910</td>\n",
       "      <td>167.077134</td>\n",
       "      <td>70.074922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>84391.200813</td>\n",
       "      <td>4.155810e+06</td>\n",
       "      <td>23.809873</td>\n",
       "      <td>11.811316</td>\n",
       "      <td>22.972317</td>\n",
       "      <td>22.770638</td>\n",
       "      <td>17.960987</td>\n",
       "      <td>23.197636</td>\n",
       "      <td>16.421255</td>\n",
       "      <td>10.651955</td>\n",
       "      <td>10.654228</td>\n",
       "      <td>10.138942</td>\n",
       "      <td>17.785183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>118192.000000</td>\n",
       "      <td>1.101776e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>218192.000000</td>\n",
       "      <td>4.875776e+06</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>55.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>318192.000000</td>\n",
       "      <td>8.474776e+06</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>73.000000</td>\n",
       "      <td>85.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>318192.000000</td>\n",
       "      <td>1.203578e+07</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>93.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>176.000000</td>\n",
       "      <td>85.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>718192.000000</td>\n",
       "      <td>1.543278e+07</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>87.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Termid       Regd No        CA_100        MTT_50       ETT_100  \\\n",
       "count   65535.000000  6.553500e+04  62969.000000  38414.000000  39699.000000   \n",
       "mean   288099.682918  8.450856e+06     63.772317     26.110637     52.052470   \n",
       "std     84391.200813  4.155810e+06     23.809873     11.811316     22.972317   \n",
       "min    118192.000000  1.101776e+06      0.000000      0.000000      0.000000   \n",
       "25%    218192.000000  4.875776e+06     54.000000     19.000000     40.000000   \n",
       "50%    318192.000000  8.474776e+06     69.000000     28.000000     56.000000   \n",
       "75%    318192.000000  1.203578e+07     81.000000     35.000000     68.000000   \n",
       "max    718192.000000  1.543278e+07    100.000000     50.000000    100.000000   \n",
       "\n",
       "            ETP_100    Course_Att          CA_1          CA_2          CA_3  \\\n",
       "count  29644.000000  59454.000000  62969.000000  62969.000000  62969.000000   \n",
       "mean      67.181892     81.046692     31.961918     15.926504      7.937985   \n",
       "std       22.770638     17.960987     23.197636     16.421255     10.651955   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       61.000000     76.000000     12.000000      3.000000      1.000000   \n",
       "50%       73.000000     85.000000     29.000000     10.000000      4.000000   \n",
       "75%       82.000000     93.000000     49.000000     24.000000     11.000000   \n",
       "max      100.000000    100.000000    100.000000     94.000000     89.000000   \n",
       "\n",
       "               CA_4        Height        Weight  \n",
       "count  62969.000000  65535.000000  65535.000000  \n",
       "mean       7.945910    167.077134     70.074922  \n",
       "std       10.654228     10.138942     17.785183  \n",
       "min        0.000000    150.000000     40.000000  \n",
       "25%        1.000000    158.000000     55.000000  \n",
       "50%        4.000000    167.000000     70.000000  \n",
       "75%       11.000000    176.000000     85.000000  \n",
       "max       87.000000    184.000000    100.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data.describe() the function shows us the different values of the statistical functions applied to the data frame.\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['O', 'A+', 'B+', 'A', 'F', 'E', 'C', 'D', 'B', 'R', 'I', 'FAIL',\n",
       "       'ReApp', 'PASS', 'M', 'S'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this cell I am a new columns which will contain either pass or fail\n",
    "abc=[]\n",
    "for i in range(0,data.shape[0]):\n",
    "    if(data.iloc[i,3])=='ReApp' or (data.iloc[i,3])=='FAIL' or (data.iloc[i,3])=='F' or (data.iloc[i,3])=='E':\n",
    "        abc.append(str('Fail'))\n",
    "    else:\n",
    "        abc.append(str('Passed'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Fail',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " 'Passed',\n",
       " ...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A        14184\n",
       "B+       12924\n",
       "A+       10946\n",
       "B         7163\n",
       "C         5710\n",
       "O         4701\n",
       "E         4378\n",
       "F         3338\n",
       "D         1674\n",
       "M          276\n",
       "I          101\n",
       "PASS        64\n",
       "R           52\n",
       "ReApp       15\n",
       "FAIL         6\n",
       "S            3\n",
       "Name: Grade, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder #We are Importing the labelencoder from the sklearn.preprocessing \n",
    "label_encoder=LabelEncoder()                   #We are just creating a variable for the function\n",
    "label_encoder.fit(abc)                         #we are fitting the label encoder on our result list\n",
    "abc=label_encoder.transform(abc)               #we are tranforming the list and storing it \n",
    "abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.DataFrame(abc,columns=['Result'])#This line Converts the abc list into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    57798\n",
       "0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Result'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 23)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([data,df1],axis=1)  #In this line, we concting two DataFrame i.e the data and justly created result DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation=df[df['MHRDName']=='Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 23)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Termid</th>\n",
       "      <th>Regd No</th>\n",
       "      <th>Course</th>\n",
       "      <th>Grade</th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>MHRDName</th>\n",
       "      <th>...</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>ScholarType</th>\n",
       "      <th>Direction</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Medium</th>\n",
       "      <th>CourseType</th>\n",
       "      <th>ProgramType</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38833</th>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>F</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38834</th>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ11</td>\n",
       "      <td>E</td>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38835</th>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ245</td>\n",
       "      <td>E</td>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38836</th>\n",
       "      <td>418192</td>\n",
       "      <td>9875776</td>\n",
       "      <td>XHQ246</td>\n",
       "      <td>B+</td>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157</td>\n",
       "      <td>72</td>\n",
       "      <td>Day Scholar</td>\n",
       "      <td>West</td>\n",
       "      <td>Male</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40904</th>\n",
       "      <td>418192</td>\n",
       "      <td>10373776</td>\n",
       "      <td>XHQ10</td>\n",
       "      <td>O</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dual Degree Bachelor of Technology - Master of...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>152</td>\n",
       "      <td>74</td>\n",
       "      <td>Hostler</td>\n",
       "      <td>North</td>\n",
       "      <td>Female</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Theory</td>\n",
       "      <td>UG</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Termid   Regd No  Course Grade  CA_100  MTT_50  ETT_100  ETP_100  \\\n",
       "38833  418192   9875776   XHQ10     F     0.0     NaN      NaN     84.0   \n",
       "38834  418192   9875776   XHQ11     E    77.0     NaN      0.0      NaN   \n",
       "38835  418192   9875776  XHQ245     E    72.0    15.0     12.0      NaN   \n",
       "38836  418192   9875776  XHQ246    B+    72.0    28.0     62.0      NaN   \n",
       "40904  418192  10373776   XHQ10     O    83.0     NaN      NaN     90.0   \n",
       "\n",
       "       Course_Att                                           MHRDName  ...  \\\n",
       "38833         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38834        94.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38835        98.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "38836        93.0  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "40904         NaN  Dual Degree Bachelor of Technology - Master of...  ...   \n",
       "\n",
       "       CA_4  Height  Weight  ScholarType  Direction  Gender    Medium  \\\n",
       "38833   0.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38834   4.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38835   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "38836   1.0     157      72  Day Scholar       West    Male  Regional   \n",
       "40904   0.0     152      74      Hostler      North  Female  Regional   \n",
       "\n",
       "      CourseType ProgramType Result  \n",
       "38833     Theory          UG      0  \n",
       "38834     Theory          UG      0  \n",
       "38835     Theory          UG      0  \n",
       "38836     Theory          UG      1  \n",
       "40904     Theory          UG      1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "validation.drop(cols,axis=1,inplace=True)\n",
    "validation_x=validation.drop(['Result'],axis=1)\n",
    "validation_y=validation['Result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Height','Weight','Direction','Course','Termid','Regd No','Gender','ProgramType'\n",
    "      ,'ScholarType','Medium','CourseType','MHRDName','Grade']\n",
    "df=df.drop(cols,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100         2566\n",
       "MTT_50        27121\n",
       "ETT_100       25836\n",
       "ETP_100       35891\n",
       "Course_Att     6081\n",
       "CA_1           2566\n",
       "CA_2           2566\n",
       "CA_3           2566\n",
       "CA_4           2566\n",
       "Result            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import Imputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "im=SimpleImputer(missing_values=np.nan, strategy='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data=im.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imputed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imputed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=df.columns\n",
    "df=pd.DataFrame(imputed_data,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['CA_100']=df['CA_100'].astype(float)\n",
    "# df['MTT_50']=df['MTT_50'].astype(float)\n",
    "# df['ETT_100']=df['ETT_100'].astype(float)\n",
    "# df['Course_Att']=df['Course_Att'].astype(float)\n",
    "# df['Result']=df['Result'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the below cell we are removing the rows which consists course as practical.  Why are we Deleting ?\n",
    "we are deleting because the data we have to predict i.e Dual Degree Bachelor of Technology - Master of Technology (Mechanical Engineering) is a theory one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>82.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>65.00000</td>\n",
       "      <td>85.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>63.00000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63.772317</td>\n",
       "      <td>26.110637</td>\n",
       "      <td>52.05247</td>\n",
       "      <td>82.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>31.961918</td>\n",
       "      <td>15.926504</td>\n",
       "      <td>7.937985</td>\n",
       "      <td>7.94591</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>68.00000</td>\n",
       "      <td>89.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.00000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CA_100     MTT_50   ETT_100  ETP_100  Course_Att       CA_1       CA_2  \\\n",
       "0  87.000000  39.000000  82.00000     89.0        88.0  41.000000  45.000000   \n",
       "1  87.000000  47.000000  65.00000     85.0        82.0  86.000000   0.000000   \n",
       "2  84.000000  29.000000  63.00000     77.0        76.0  76.000000   0.000000   \n",
       "3  63.772317  26.110637  52.05247     82.0        74.0  31.961918  15.926504   \n",
       "4  87.000000  34.000000  68.00000     89.0        76.0  42.000000  26.000000   \n",
       "\n",
       "       CA_3      CA_4  Result  \n",
       "0  1.000000   0.00000     1.0  \n",
       "1  0.000000   1.00000     1.0  \n",
       "2  3.000000   5.00000     1.0  \n",
       "3  7.937985   7.94591     1.0  \n",
       "4  2.000000  17.00000     1.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        float64\n",
       "MTT_50        float64\n",
       "ETT_100       float64\n",
       "ETP_100       float64\n",
       "Course_Att    float64\n",
       "CA_1          float64\n",
       "CA_2          float64\n",
       "CA_3          float64\n",
       "CA_4          float64\n",
       "Result        float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data.isnull().sum(axis=1)<3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA_100        0\n",
       "MTT_50        0\n",
       "ETT_100       0\n",
       "ETP_100       0\n",
       "Course_Att    0\n",
       "CA_1          0\n",
       "CA_2          0\n",
       "CA_3          0\n",
       "CA_4          0\n",
       "Result        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    57798\n",
       "0.0     7737\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['Result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535, 10)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=train_data.dropna()\n",
    "arr=result['Result']\n",
    "result=result.drop(['Result'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc=ss.fit_transform(result)\n",
    "abc.reshape(-1,1)\n",
    "abc.shape\n",
    "cols=result.columns\n",
    "result=pd.DataFrame(abc,columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>1.425380e+00</td>\n",
       "      <td>1.674976e+00</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>0.406454</td>\n",
       "      <td>3.974745e-01</td>\n",
       "      <td>1.806207</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-0.760849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>2.310066e+00</td>\n",
       "      <td>7.241599e-01</td>\n",
       "      <td>1.163488</td>\n",
       "      <td>0.055725</td>\n",
       "      <td>2.376473e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-0.665095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.666940e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>6.122992e-01</td>\n",
       "      <td>0.641104</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>1.936696e+00</td>\n",
       "      <td>-0.989443</td>\n",
       "      <td>-4.729303e-01</td>\n",
       "      <td>-0.282081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.044457e-16</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.967594</td>\n",
       "      <td>-0.411912</td>\n",
       "      <td>-1.562403e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.506435e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.952347e-01</td>\n",
       "      <td>8.724513e-01</td>\n",
       "      <td>8.919510e-01</td>\n",
       "      <td>1.424680</td>\n",
       "      <td>-0.295003</td>\n",
       "      <td>4.414522e-01</td>\n",
       "      <td>0.625822</td>\n",
       "      <td>-5.687043e-01</td>\n",
       "      <td>0.866961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CA_100        MTT_50       ETT_100   ETP_100  Course_Att  \\\n",
       "0  9.952347e-01  1.425380e+00  1.674976e+00  1.424680    0.406454   \n",
       "1  9.952347e-01  2.310066e+00  7.241599e-01  1.163488    0.055725   \n",
       "2  8.666940e-01  3.195225e-01  6.122992e-01  0.641104   -0.295003   \n",
       "3  3.044457e-16  3.928796e-16 -3.974090e-16  0.967594   -0.411912   \n",
       "4  9.952347e-01  8.724513e-01  8.919510e-01  1.424680   -0.295003   \n",
       "\n",
       "           CA_1      CA_2          CA_3      CA_4  \n",
       "0  3.974745e-01  1.806207 -6.644782e-01 -0.760849  \n",
       "1  2.376473e+00 -0.989443 -7.602521e-01 -0.665095  \n",
       "2  1.936696e+00 -0.989443 -4.729303e-01 -0.282081  \n",
       "3 -1.562403e-16  0.000000 -8.506435e-17  0.000000  \n",
       "4  4.414522e-01  0.625822 -5.687043e-01  0.866961  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "      <td>6.553500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.745519e-15</td>\n",
       "      <td>-1.782266e-15</td>\n",
       "      <td>-2.145025e-16</td>\n",
       "      <td>6.155271e-16</td>\n",
       "      <td>-3.926856e-15</td>\n",
       "      <td>9.516526e-16</td>\n",
       "      <td>-7.370434e-16</td>\n",
       "      <td>-6.777959e-16</td>\n",
       "      <td>-1.110574e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "      <td>1.000008e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.732447e+00</td>\n",
       "      <td>-2.887465e+00</td>\n",
       "      <td>-2.911313e+00</td>\n",
       "      <td>-4.386848e+00</td>\n",
       "      <td>-4.737561e+00</td>\n",
       "      <td>-1.405613e+00</td>\n",
       "      <td>-9.894431e-01</td>\n",
       "      <td>-7.602521e-01</td>\n",
       "      <td>-7.608488e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-4.187137e-01</td>\n",
       "      <td>-1.228206e-01</td>\n",
       "      <td>-2.934656e-03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-2.365482e-01</td>\n",
       "      <td>-8.339024e-01</td>\n",
       "      <td>-8.030664e-01</td>\n",
       "      <td>-6.644782e-01</td>\n",
       "      <td>-6.650953e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.811432e-01</td>\n",
       "      <td>3.928796e-16</td>\n",
       "      <td>-3.974090e-16</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.141801e-01</td>\n",
       "      <td>-4.230298e-02</td>\n",
       "      <td>-3.060618e-01</td>\n",
       "      <td>-3.771564e-01</td>\n",
       "      <td>-3.778347e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.953063e-01</td>\n",
       "      <td>3.195225e-01</td>\n",
       "      <td>4.445082e-01</td>\n",
       "      <td>2.493151e-01</td>\n",
       "      <td>6.402726e-01</td>\n",
       "      <td>7.053187e-01</td>\n",
       "      <td>5.015706e-01</td>\n",
       "      <td>2.932612e-01</td>\n",
       "      <td>2.924399e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.552245e+00</td>\n",
       "      <td>2.641824e+00</td>\n",
       "      <td>2.681722e+00</td>\n",
       "      <td>2.142959e+00</td>\n",
       "      <td>1.107910e+00</td>\n",
       "      <td>2.992162e+00</td>\n",
       "      <td>4.850360e+00</td>\n",
       "      <td>7.763629e+00</td>\n",
       "      <td>7.569707e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CA_100        MTT_50       ETT_100       ETP_100    Course_Att  \\\n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04   \n",
       "mean   1.745519e-15 -1.782266e-15 -2.145025e-16  6.155271e-16 -3.926856e-15   \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00   \n",
       "min   -2.732447e+00 -2.887465e+00 -2.911313e+00 -4.386848e+00 -4.737561e+00   \n",
       "25%   -4.187137e-01 -1.228206e-01 -2.934656e-03  0.000000e+00 -2.365482e-01   \n",
       "50%    1.811432e-01  3.928796e-16 -3.974090e-16  0.000000e+00  1.141801e-01   \n",
       "75%    6.953063e-01  3.195225e-01  4.445082e-01  2.493151e-01  6.402726e-01   \n",
       "max    1.552245e+00  2.641824e+00  2.681722e+00  2.142959e+00  1.107910e+00   \n",
       "\n",
       "               CA_1          CA_2          CA_3          CA_4  \n",
       "count  6.553500e+04  6.553500e+04  6.553500e+04  6.553500e+04  \n",
       "mean   9.516526e-16 -7.370434e-16 -6.777959e-16 -1.110574e-15  \n",
       "std    1.000008e+00  1.000008e+00  1.000008e+00  1.000008e+00  \n",
       "min   -1.405613e+00 -9.894431e-01 -7.602521e-01 -7.608488e-01  \n",
       "25%   -8.339024e-01 -8.030664e-01 -6.644782e-01 -6.650953e-01  \n",
       "50%   -4.230298e-02 -3.060618e-01 -3.771564e-01 -3.778347e-01  \n",
       "75%    7.053187e-01  5.015706e-01  2.932612e-01  2.924399e-01  \n",
       "max    2.992162e+00  4.850360e+00  7.763629e+00  7.569707e+00  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65535,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=result\n",
    "y=arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52428, 9)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=y_train.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes =np.linspace(0.1,1,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=x_train\n",
    "y=y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr3=LogisticRegression(solver='liblinear',C=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr3.fit(x_train,y_train)\n",
    "y_pred3=lr3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9742885481040665\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test,y_pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "train_sizes, train_scores, validation_scores = learning_curve(estimator =lr,\n",
    "                                                              X = X,\n",
    "                                                              y = y,\n",
    "                                                              train_sizes = train_sizes,\n",
    "                                                              cv = 8,\n",
    "                                                              random_state=95,\n",
    "                                                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97536516, 0.97318509, 0.97318509, 0.97318509, 0.97318509,\n",
       "        0.97318509, 0.97318509, 0.97318509],\n",
       "       [0.97358131, 0.97424893, 0.97300906, 0.97300906, 0.97300906,\n",
       "        0.97300906, 0.97300906, 0.97300906],\n",
       "       [0.97326497, 0.97308185, 0.97210523, 0.9728377 , 0.9728377 ,\n",
       "        0.9728377 , 0.9728377 , 0.9728377 ],\n",
       "       [0.97226336, 0.97271218, 0.97181455, 0.97302635, 0.97311611,\n",
       "        0.97311611, 0.97311611, 0.97311611],\n",
       "       [0.97310054, 0.97299407, 0.97246176, 0.97341992, 0.97295859,\n",
       "        0.9720714 , 0.9720714 , 0.9720714 ],\n",
       "       [0.97294363, 0.97297297, 0.97241541, 0.97358922, 0.97273821,\n",
       "        0.97265017, 0.97267952, 0.97267952],\n",
       "       [0.97323327, 0.9732833 , 0.97270794, 0.9737586 , 0.97308318,\n",
       "        0.97305816, 0.97313321, 0.97288305],\n",
       "       [0.97384139, 0.97388499, 0.9736016 , 0.97423377, 0.9737542 ,\n",
       "        0.97384139, 0.97392859, 0.97294764]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.97512969, 0.96933171, 0.97451938, 0.96704303, 0.97070491,\n",
       "        0.97192554, 0.97115385, 0.9739011 ],\n",
       "       [0.97390906, 0.97055233, 0.97589258, 0.97055233, 0.97238328,\n",
       "        0.97329875, 0.97298535, 0.97557998],\n",
       "       [0.9743668 , 0.97162038, 0.97604516, 0.96856881, 0.97162038,\n",
       "        0.97253586, 0.97130647, 0.97481685],\n",
       "       [0.97406164, 0.97131523, 0.97635032, 0.96948428, 0.97253586,\n",
       "        0.97329875, 0.97252747, 0.97588523],\n",
       "       [0.97360391, 0.97207812, 0.97665548, 0.96963686, 0.97284101,\n",
       "        0.97284101, 0.97237485, 0.97542735],\n",
       "       [0.97375648, 0.97177296, 0.9765029 , 0.96994202, 0.97299359,\n",
       "        0.97299359, 0.97237485, 0.97588523],\n",
       "       [0.97375648, 0.9722307 , 0.97635032, 0.96994202, 0.97314617,\n",
       "        0.97299359, 0.97237485, 0.97588523],\n",
       "       [0.97360391, 0.97314617, 0.97635032, 0.97024718, 0.97345133,\n",
       "        0.97360391, 0.9726801 , 0.97588523]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training scores\n",
      "\n",
      " 4587     0.973458\n",
      "10485    0.973236\n",
      "16383    0.972830\n",
      "22281    0.972785\n",
      "28179    0.972644\n",
      "34077    0.972834\n",
      "39975    0.973143\n",
      "45874    0.973754\n",
      "dtype: float64\n",
      "\n",
      " --------------------\n",
      "\n",
      "Mean validation scores\n",
      "\n",
      " 4587     0.971714\n",
      "10485    0.973144\n",
      "16383    0.972610\n",
      "22281    0.973182\n",
      "28179    0.973182\n",
      "34077    0.973278\n",
      "39975    0.973335\n",
      "45874    0.973621\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = validation_scores.mean(axis =1 )\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 20) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 800x550 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shiva Chandra\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "y_pred=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974517433432517"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.86      0.89      1531\n",
      "         1.0       0.98      0.99      0.99     11576\n",
      "\n",
      "    accuracy                           0.97     13107\n",
      "   macro avg       0.95      0.92      0.94     13107\n",
      "weighted avg       0.97      0.97      0.97     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier(criterion='gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes =np.linspace(0.1,1,10)\n",
    "X=x_train\n",
    "y=y_train\n",
    "train_sizes, train_scores, valid_scores = learning_curve( dt, X, y, train_sizes=train_sizes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training scores\n",
      "\n",
      " 4718     0.997117\n",
      "9436     0.996280\n",
      "14155    0.996072\n",
      "18873    0.996021\n",
      "23592    0.995888\n",
      "28310    0.995722\n",
      "33028    0.995740\n",
      "37747    0.995896\n",
      "42465    0.995928\n",
      "47184    0.996007\n",
      "dtype: float64\n",
      "\n",
      " --------------------\n",
      "\n",
      "Mean validation scores\n",
      "\n",
      " 4718     0.970169\n",
      "9436     0.973907\n",
      "14155    0.975910\n",
      "18873    0.978161\n",
      "23592    0.978447\n",
      "28310    0.978046\n",
      "33028    0.979248\n",
      "37747    0.979439\n",
      "42465    0.979439\n",
      "47184    0.979133\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = valid_scores.mean(axis =1 )\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 20) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.fit(x_train,y_train)\n",
    "y_pred=dt.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9813839932860303"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1438,   151],\n",
       "       [   93, 11425]], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.94      0.92      1531\n",
      "         1.0       0.99      0.99      0.99     11576\n",
      "\n",
      "    accuracy                           0.98     13107\n",
      "   macro avg       0.95      0.96      0.96     13107\n",
      "weighted avg       0.98      0.98      0.98     13107\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CA_100</th>\n",
       "      <th>MTT_50</th>\n",
       "      <th>ETT_100</th>\n",
       "      <th>ETP_100</th>\n",
       "      <th>Course_Att</th>\n",
       "      <th>CA_1</th>\n",
       "      <th>CA_2</th>\n",
       "      <th>CA_3</th>\n",
       "      <th>CA_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38833</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38834</th>\n",
       "      <td>77.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38835</th>\n",
       "      <td>72.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38836</th>\n",
       "      <td>72.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40904</th>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>68.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40905</th>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40906</th>\n",
       "      <td>95.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40907</th>\n",
       "      <td>97.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>83.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CA_100  MTT_50  ETT_100  ETP_100  Course_Att  CA_1  CA_2  CA_3  CA_4\n",
       "38833     0.0     NaN      NaN     84.0         NaN   0.0   0.0   0.0   0.0\n",
       "38834    77.0     NaN      0.0      NaN        94.0  29.0  44.0   0.0   4.0\n",
       "38835    72.0    15.0     12.0      NaN        98.0  53.0   3.0  15.0   1.0\n",
       "38836    72.0    28.0     62.0      NaN        93.0  55.0  14.0   2.0   1.0\n",
       "40904    83.0     NaN      NaN     90.0         NaN  68.0   9.0   6.0   0.0\n",
       "40905    87.0     NaN     60.0      NaN        84.0  73.0   7.0   1.0   6.0\n",
       "40906    95.0    43.0     83.0      NaN        78.0  42.0  18.0  20.0  15.0\n",
       "40907    97.0    48.0     73.0      NaN        83.0  58.0   4.0  11.0  24.0"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , 33.5       , 48.33333333, 84.        , 88.33333333,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [77.        , 33.5       ,  0.        , 87.        , 94.        ,\n",
       "        29.        , 44.        ,  0.        ,  4.        ],\n",
       "       [72.        , 15.        , 12.        , 87.        , 98.        ,\n",
       "        53.        ,  3.        , 15.        ,  1.        ],\n",
       "       [72.        , 28.        , 62.        , 87.        , 93.        ,\n",
       "        55.        , 14.        ,  2.        ,  1.        ],\n",
       "       [83.        , 33.5       , 48.33333333, 90.        , 88.33333333,\n",
       "        68.        ,  9.        ,  6.        ,  0.        ],\n",
       "       [87.        , 33.5       , 60.        , 87.        , 84.        ,\n",
       "        73.        ,  7.        ,  1.        ,  6.        ],\n",
       "       [95.        , 43.        , 83.        , 87.        , 78.        ,\n",
       "        42.        , 18.        , 20.        , 15.        ],\n",
       "       [97.        , 48.        , 73.        , 87.        , 83.        ,\n",
       "        58.        ,  4.        , 11.        , 24.        ]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_x=im.fit_transform(validation_x)\n",
    "validation_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_x=ss.fit_transform(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=dt.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38833    0\n",
       "38834    0\n",
       "38835    0\n",
       "38836    1\n",
       "40904    1\n",
       "40905    1\n",
       "40906    1\n",
       "40907    1\n",
       "Name: Result, dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(validation_y,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "svm=SVC(kernel='linear',C=1.0)\n",
    "lr1=LogisticRegression(solver='liblinear',C=0.02)\n",
    "dt1=DecisionTreeClassifier()\n",
    "vc=VotingClassifier(estimators=[('lr',lr1),('dt',dt1),('svm',svm)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=0.02, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='warn',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='liblinear', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('dt',\n",
       "                              DecisionTreeClassifier(class_weight=None,\n",
       "                                                     criterion='gini',\n",
       "                                                     max_depth...\n",
       "                                                     min_weight_fraction_leaf=0.0,\n",
       "                                                     presort=False,\n",
       "                                                     random_state=None,\n",
       "                                                     splitter='best')),\n",
       "                             ('svm',\n",
       "                              SVC(C=1.0, cache_size=200, class_weight=None,\n",
       "                                  coef0=0.0, decision_function_shape='ovr',\n",
       "                                  degree=3, gamma='auto_deprecated',\n",
       "                                  kernel='linear', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vc.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=vc.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.976424811169604"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "train_sizes =np.linspace(0.1,1,10)\n",
    "X=x_train\n",
    "y=y_train\n",
    "train_sizes, train_scores, valid_scores = learning_curve( vc, X, y, train_sizes=train_sizes, cv=10,scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'accuracy', 'roc_auc', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'brier_score_loss', 'adjusted_rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "metrics.SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean training scores\n",
      "\n",
      " 4718     0.987081\n",
      "9436     0.986812\n",
      "14155    0.986923\n",
      "18873    0.987014\n",
      "23592    0.986745\n",
      "28310    0.986632\n",
      "33028    0.986615\n",
      "37747    0.986678\n",
      "42465    0.986887\n",
      "47184    0.987120\n",
      "dtype: float64\n",
      "\n",
      " --------------------\n",
      "\n",
      "Mean validation scores\n",
      "\n",
      " 4718     0.985127\n",
      "9436     0.985552\n",
      "14155    0.986321\n",
      "18873    0.986299\n",
      "23592    0.986475\n",
      "28310    0.986443\n",
      "33028    0.986294\n",
      "37747    0.986422\n",
      "42465    0.986558\n",
      "47184    0.986662\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "train_scores_mean = train_scores.mean(axis = 1)\n",
    "validation_scores_mean = valid_scores.mean(axis =1 )\n",
    "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
    "print('\\n', '-' * 20) # separator\n",
    "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n",
    "plt.plot(train_sizes, validation_scores_mean, label = 'Validation error')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=Sequential()\n",
    "# 1st Convolutional Layer\n",
    "classifier.add(Dense(output_dim=8,init='uniform',input_dim=9,activation='relu'))\n",
    "classifier.add(Dense(output_dim=6,init='uniform',activation='relu'))\n",
    "classifier.add(Dense(output_dim=3,init='uniform',activation='relu'))\n",
    "\n",
    "#output layer\n",
    "classifier.add(Dense(output_dim=1,activation='sigmoid'))\n",
    "\n",
    "classifier.summary()\n",
    "\n",
    "classifier.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=classifier.fit(x_train,y_train,verbose=1,validation_split=0.1,nb_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=(y_pred>0.5)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the graphs of Accuracy and Loss of ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot training & validation accuracy values\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=classifier.predict(validation_x)\n",
    "predictions=(predictions>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(validation_y,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(validation_y,predictions)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab as pl\n",
    "pl.matshow(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
